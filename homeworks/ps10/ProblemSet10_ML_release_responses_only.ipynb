{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d0bb5b",
   "metadata": {},
   "source": [
    "## <a name=\"contributors\"></a> 0. Credit for Contributors\n",
    "\n",
    "List the various students, lecture notes, or online resouces that helped you complete this problem set:\n",
    "\n",
    "Ex: I worked with Bob on the cat neural network problem.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd6806a",
   "metadata": {},
   "source": [
    "No other contributors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75772176",
   "metadata": {},
   "source": [
    "### <a name=\"NB_observations\"></a> 1D. Observations (10 points)\n",
    "\n",
    "**Observations of s:** Estimating $s$ from data is heavily reliant on the sizes of the data. In the real world, it's often difficult to find good training examples for ham, since nobody wants to give out their private email for the world to read. As a result, spam datasets often have many more spam examples than ham examples. By fixing $s$ manually, we can adjust how much the algorithm favors catching spam at the expense of falsely flagging a ham message. Try setting $s$ to a few values manually, and briefly explain what happens to your performance as $s$ increases and decreases.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a1a7ff",
   "metadata": {},
   "source": [
    "As s increases, the model becomes more biased toward classifying messages as spam. This leads to higher spam recall (catching more spam) but also more false positives (legitimate messages incorrectly flagged as spam). Conversely, decreasing s makes the classifier more conservative, reducing false positives but allowing more spam to slip through. The optimal s depends on the application. Most users prefer lower s since missing a legitimate email is typically worse than seeing occasional spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd8bb02",
   "metadata": {},
   "source": [
    "**Observations of k:** Finally, the Laplace smoothing parameter is critical for handling unseen words during testing by assigning them a small nonzero probability. However, it also imposes a uniform prior, which smoothens the estimated probabilities of observed words. In the previous code block, we estimated the Naive Bayes parameters using $k = 1$. Experiment with a range of $k$ values and identify the value of $k$ that results in the highest accuracy. Briefly explain how $k$ affects the model's performance.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf175fcf",
   "metadata": {},
   "source": [
    "Through experimentation, k ≈ 1 typically yields the highest accuracy. When k is too small, the model becomes overly sensitive to rare or unseen words and may overfit to the training vocabulary. When k is too large, the probabilities are smoothed too heavily toward uniform, causing the model to lose its ability to discriminate between spam-indicative and ham-indicative words. A moderate value like k = 1 balances preserving the discriminative signal from training data while providing robustness to unseen words during testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcab3a6",
   "metadata": {},
   "source": [
    "### <a name=\"learning_rate\"></a> 2C. Learning Rate (10 points)\n",
    "\n",
    "Try varying the learning rate parameter `alpha` in your run above, e.g. 0.001, 0.005, 0.01, 0.05, 0.1, 0.5.\n",
    "- What are the best learning rates for each of the 3 gradient descent variants? What happens when the learning rate is too small? What about too large?\n",
    "- Which method is more robust to large learning rates?\n",
    "- Which method converges fastest when the learning rate is optimal?\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3718e59",
   "metadata": {},
   "source": [
    "Batch GD: Works well with α ≈ 0.1-0.5. Since it uses the full dataset for each update, the gradient is stable and can tolerate larger learning rates.\n",
    "Stochastic GD: Works best with smaller α ≈ 0.01-0.05. Individual sample gradients are noisy, so large learning rates cause erratic updates.\n",
    "Mini-Batch GD: Performs well with α ≈ 0.05-0.1. It balances between batch and SGD, allowing moderate learning rates.\n",
    "\n",
    "Batch gradient descent is the most robust to large learning rates because it computes the exact gradient over the entire dataset, resulting in stable and consistent updates. SGD is the least robust since single-sample gradients have high variance, and large learning rates amplify this noise, causing erratic behavior.\n",
    "\n",
    "Stochastic gradient descent typically converges fastest in terms of epochs because it makes N updates per epoch (one per sample), allowing it to make rapid progress early in training. However, it may oscillate near the minimum. Mini-batch GD often provides the best practical tradeoff—faster than batch GD while being more stable than pure SGD."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
