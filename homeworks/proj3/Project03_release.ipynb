{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc1c944",
   "metadata": {},
   "source": [
    "**This project is due Wednesday, December 03, 2025 at 11:59 pm. Please plan ahead and submit your work on time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835550af",
   "metadata": {
    "id": "835550af"
   },
   "source": [
    "<center><h1>Grad Project #3</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136538f6-da03-4d1c-a5be-ae19a4e5862f",
   "metadata": {},
   "source": [
    "In this project, continuing with the \"search and rescue\" domain, we will consider the problem of inferring the location of the robot as it moves around. Specifically, you will:\n",
    "\n",
    "* Implement a particle filter for the localization problem, to allow the robot to estimate its position. \n",
    "* Implement a particle filter for the simultaneous localization and mapping (SLAM) problem, to allow the robot *both* to estimate its position and the map of its environment.  \n",
    "* Run simulations to test the performance of your algorithms.\n",
    "\n",
    "Your project will consist of implementing a particle filter, and also performing experiments and analysis on the different implementations. Your project submission will consist of the code you implement, a PDF of your experiments, and the movies we've asked you to generate.\n",
    "\n",
    "Your project grade will be based on the autograded tests, report (with figures), animation, and notebook as a whole. \n",
    "\n",
    "0. [Credit for Contributors (required)](#contributors)\n",
    "1. [Noise Sampling (12 points)](#sampling)\n",
    "    1. [Sampling Warmups (2 points)](#warmups)\n",
    "        1. [Warmup 1 (1 point)](#warmup1)\n",
    "        2. [Warmup 2 (1 point)](#warmup2)\n",
    "    2. [Adding Motion Noise (10 points)](#motion_noise)\n",
    "        1. [Experiment 1: Sampling from Multivariate Gaussian (5 points)](#multivariate)\n",
    "        2. [Experiment 2: Motion Noise (5 points)](#noise)\n",
    "2. [Particle Filter Localization (48 points)](#pf_localization)\n",
    "    1. [Motion Model (28 points)](#motion_model)\n",
    "        1. [Motion Model Implementation (3 points)](#motion_imp)\n",
    "        2. [Experiment 3: Noisy Motion (5 points)](#exp3)\n",
    "        3. [Experiment 4: Less Noisy Motion (5 points)](#exp4)\n",
    "        4. [Experiment 5: Finer Motion (5 points)](#exp5)\n",
    "        5. [Experiment 6: Adjusting Noise for Finer Motion (5 points)](#exp6)\n",
    "        6. [Experiment 7: Unbalanced Noise (5 points)](#exp7)\n",
    "    2. [Localization: Computing the Importance Weights (10 points)](#localization_importance)\n",
    "    3. [Localization: Particle Filter Update (5 points)](#localization_pfupdate)\n",
    "    4. [Evaluating Particle Filter-based Localization (5 points)](#evaluating_pf_localization)\n",
    "        1. [Experiment 8: Running the Localization Particle Filter (5 points)](#exp8)\n",
    "3. [Particle Filter SLAM (40 points)](#pf_slam)\n",
    "    1. [SLAM: Update by Motion Model (5 points)](#slam_motion_model)\n",
    "    2. [SLAM: Tracking New Landmarks (10 points)](#slam_tracking)\n",
    "    3. [SLAM: Computing the Importance Weight (10 points)](#slam_importance)\n",
    "    4. [SLAM: Particle Filter Update (5 points)](#slam_pf_update)\n",
    "    5. [Evaluating Particle Filter-based SLAM (10 points)](#evaluating_pf_slam)\n",
    "        1. [Experiment 9: Running the SLAM Particle Filter (5 points)](#exp9)\n",
    "        2. [Experiment 10: More Fun with the SLAM Particle Filter (5 points)](#exp10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e93484",
   "metadata": {},
   "source": [
    "# <a id=\"contributors\"></a> 0. Credit for Contributors\n",
    "\n",
    "List the various students, lecture notes, or online resouces that helped you complete this project:\n",
    "\n",
    "Ex: I worked with Bob on Sampling.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e540a4d",
   "metadata": {},
   "source": [
    "--> *(double click on this cell to delete this text and type your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0577d59f",
   "metadata": {},
   "source": [
    "# Imports and Utilities\n",
    "\n",
    "These are import and utility functions, and also scaffolding of functions that we have provided for you for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca16247",
   "metadata": {
    "id": "dca16247"
   },
   "outputs": [],
   "source": [
    "# Setup matplotlib animation\n",
    "import matplotlib\n",
    "matplotlib.rc('animation', html='jshtml')\n",
    "import random; import numpy.random; random.seed(0); numpy.random.seed(0);\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from principles_of_autonomy.grader import Grader\n",
    "from principles_of_autonomy.notebook_tests.proj_3 import TestProj3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a33be",
   "metadata": {
    "id": "0c8a33be"
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "def implementation_for(cls, method_name: Optional[str] = None):\n",
    "    \"\"\"Helper to provide a concrete implementation for a class method.\n",
    "\n",
    "    This utility allows one to define methods outside of a class defintion.\n",
    "    Thus allowing one to provide the implementations of a class \"incrementally\".\n",
    "    This utility is useful for gradually submitting class method implementations\n",
    "    to catsoop.\n",
    "\n",
    "    It is intended to be used as a decorator.\n",
    "\n",
    "    Args:\n",
    "        cls: a Python class on which we are implementing the method.\n",
    "        method_name: an optional method name to indicate which method we are\n",
    "            implementing. If not provided, infer the method name by using the\n",
    "            decorated function's name.\n",
    "\n",
    "    Example:\n",
    "        >>> class A:\n",
    "        ...   def foo(self):\n",
    "        ...     raise NotImplementedError()\n",
    "\n",
    "        >>> @implementation_for(A)\n",
    "        ... def foo(self):\n",
    "        ...   print(\"implemented foo!\")\n",
    "\n",
    "        >>> A().foo()\n",
    "        implemented foo!\n",
    "    \"\"\"\n",
    "\n",
    "    def decorator(meth: Callable) -> Callable:\n",
    "        mname = method_name or meth.__name__\n",
    "        setattr(cls, mname, meth)\n",
    "        return meth\n",
    "\n",
    "    return decorator\n",
    "\n",
    "\n",
    "\n",
    "from typing import (Callable, Iterable, List, Sequence, Optional, Dict)\n",
    "\n",
    "from abc import abstractmethod, ABCMeta\n",
    "import itertools\n",
    "import math\n",
    "import random\n",
    "import dataclasses\n",
    "from collections import namedtuple\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats\n",
    "import scipy.special\n",
    "\n",
    "# Basic data structures.\n",
    "\n",
    "# x, y coordinate and the rotation of the robot.\n",
    "Pose = namedtuple(\"Pose\", [\"x\", \"y\", \"theta\"])\n",
    "# unique id (str) and x, y coordinate of the landmark.\n",
    "Landmark = namedtuple(\"Landmark\", [\"id\", \"x\", \"y\"])\n",
    "# r --- distance to the landmark; b --- angle to the landmark, computed by arctan2.\n",
    "Measurement = namedtuple(\"Measurement\", [\"landmark_id\", \"r\", \"b\"])\n",
    "# delta_p --- distance to move; delta_theta --- rotation of the robot\n",
    "Command = namedtuple(\"Command\", [\"delta_p\", \"delta_theta\"])\n",
    "\n",
    "\n",
    "def grid_of_landmarks(\n",
    "        x_range: Iterable[float] = range(-4, 20, 4),\n",
    "        y_range: Iterable[float] = range(-4, 20, 4),\n",
    ") -> Sequence[Landmark]:\n",
    "    \"\"\"Constructs a grid of landmarks from a catesion product of x and y coordinates.\"\"\"\n",
    "    return tuple(\n",
    "        Landmark(f\"landmark-{i}\", *loc)\n",
    "        for i, loc in enumerate(itertools.product(x_range, y_range)))\n",
    "\n",
    "\n",
    "class Inference(metaclass=ABCMeta):\n",
    "    \"\"\"Interface for an inference algorithm (localization or SLAM variants).\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def estimated_pose(self) -> Pose:\n",
    "        \"\"\"Returns the current estimation of the robot's Pose.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def estimated_landmarks(self) -> Sequence[Landmark]:\n",
    "        \"\"\"Returns the current estimation of the landmarks.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def init(self, init_state: Pose) -> None:\n",
    "        \"\"\"Initialize the inference with an initial pose.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def update(self, measurements: Sequence[Measurement]) -> None:\n",
    "        \"\"\"An update step of the inference, called after every simulation step.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def plot_state(self, ax) -> None:\n",
    "        \"\"\"Helper to visualize the internal state of the inference algorithm.\"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "def normalize_angles(angles: np.array) -> np.ndarray:\n",
    "    \"\"\"Given an array of angles in radians, element-wise normalize the angles to the range [-pi, pi].\n",
    "\n",
    "    Args:\n",
    "        angles: array of any shape.\n",
    "\n",
    "    Returns:\n",
    "        normalized angles, array of same shape as the input.\n",
    "    \"\"\"\n",
    "    return np.arctan2(np.sin(angles), np.cos(angles))\n",
    "\n",
    "\n",
    "def circular_mean(angles: np.array, axis=None) -> float:\n",
    "    \"\"\"Given an array of angles in radians, find the [circular mean](https://en.wikipedia.org/wiki/Circular_mean).\n",
    "\n",
    "    Args:\n",
    "        angles: array of any shape.\n",
    "        axis: axis or axes along which the means are computed. The default is to compute the mean of the flattened array.\n",
    "\n",
    "    Returns:\n",
    "        mean of the angles, normalized to [-pi, pi].\n",
    "    \"\"\"\n",
    "    return np.arctan2(np.sum(np.sin(angles), axis=axis),\n",
    "                      np.sum(np.cos(angles), axis=axis))\n",
    "\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class SimulationResult:\n",
    "    \"\"\"A helper class to hold the results of running a simulation.\"\"\"\n",
    "    sim: 'Simulator'  # Simulator that generated this result\n",
    "    infer: Optional[Inference]  # Inference procedure that generated this result\n",
    "    true_poses: Sequence[Pose]\n",
    "    estimated_poses: Optional[Sequence[Pose]] = None\n",
    "    # History snapshots for the Inference, for animation purpose\n",
    "    snapshots: Optional[Sequence[Inference]] = None\n",
    "\n",
    "\n",
    "@dataclasses.dataclass(frozen=False)\n",
    "class Simulator:\n",
    "    \"\"\"A simulator for a point robot in R^2.\n",
    "\n",
    "    The simulator simulates the motion and sensor noises of the robot by\n",
    "    sampling from 2D Gaussians.\n",
    "    The simulation has a list of landmarks, each with a unique identifier.\n",
    "    The sensor of the robot can sense, for each landmark in the robot's sensing\n",
    "    range, a noise-corrupted distance and bearing to that landmarks (together\n",
    "    with the identifier that identifies the landmark).\n",
    "    \"\"\"\n",
    "\n",
    "    # Initial simulator state\n",
    "    init_state: Pose = Pose(0, 0, 0)\n",
    "\n",
    "    # 2x2 covariance matrix of the motion noise.\n",
    "    motion_noise_covariance: np.ndarray = np.diag([1e-3, np.deg2rad(3)**2])\n",
    "\n",
    "    # 2x2 covariance matrix of the sensor noise.\n",
    "    sensor_noise_covariance: np.ndarray = np.diag([1, np.deg2rad(5)**2])\n",
    "\n",
    "    # A set of landmarks\n",
    "    landmarks: Sequence[Landmark] = grid_of_landmarks()\n",
    "\n",
    "    # Robot can only sense landmarks within this range\n",
    "    max_sensing_range: float = np.inf\n",
    "\n",
    "    # Current state of the robot\n",
    "    state: Pose = dataclasses.field(init=False, default=None)\n",
    "\n",
    "    # Random seed control\n",
    "    rng: np.random.Generator = dataclasses.field(init=False, default=None)\n",
    "    # Using the same seed will induce the same trajectory\n",
    "    seed: dataclasses.InitVar[int] = 0\n",
    "\n",
    "    def __post_init__(self, seed: int):\n",
    "        assert (len({l.id for l in self.landmarks\n",
    "                    }) == len(self.landmarks)), \"Landmark must have unique IDs\"\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "    def init(self) -> None:\n",
    "        self.state = self.init_state\n",
    "\n",
    "    def simulate_motion(self, command: Command) -> None:\n",
    "        \"\"\"Simulate robot motion. This function updates the value of\n",
    "        self.state.\n",
    "\n",
    "        Args:\n",
    "          command: a Command tuple containing fields delta_p(float), the\n",
    "          distance of the movement, and delta_theta(float), the rotation of\n",
    "          the movement.\n",
    "        \"\"\"\n",
    "        noise = self.rng.multivariate_normal(np.zeros(2),\n",
    "                                             self.motion_noise_covariance)\n",
    "        x = (self.state.x + math.cos(self.state.theta) *\n",
    "             (command.delta_p + noise[0]))\n",
    "        y = (self.state.y + math.sin(self.state.theta) *\n",
    "             (command.delta_p + noise[0]))\n",
    "        theta = self.state.theta + command.delta_theta + noise[1]\n",
    "        self.state = Pose(x, y, theta)\n",
    "\n",
    "    def simulate_sensing(self) -> Sequence[Measurement]:\n",
    "        \"\"\"Simulate the robot sensing process. This function returns a list of\n",
    "        measurements, in the same order as the self.landmarks list.\n",
    "        Specifically, it measures the distance and the angle w.r.t. each\n",
    "        landmark, and add a Gaussian noise on the measurement.\n",
    "\n",
    "        Returns:\n",
    "          measurements: a list of measurements.\n",
    "        \"\"\"\n",
    "        measurements = []\n",
    "        # Simulate that the measurements' order is random\n",
    "        for landmark in sorted(self.landmarks, key=lambda _: random.random()):\n",
    "            r = math.hypot(landmark.x - self.state.x, landmark.y - self.state.y)\n",
    "\n",
    "            if r >= self.max_sensing_range:\n",
    "                # Can't sense this landmark, skip\n",
    "                continue\n",
    "\n",
    "            b = math.atan2(landmark.y - self.state.y,\n",
    "                           landmark.x - self.state.x) - self.state.theta\n",
    "            # Normalize angle to -pi to pi\n",
    "            b = math.atan2(math.sin(b), math.cos(b))\n",
    "\n",
    "            noise = self.rng.multivariate_normal(np.zeros(2),\n",
    "                                                 self.sensor_noise_covariance)\n",
    "\n",
    "            measurements.append(\n",
    "                Measurement(landmark.id, r + noise[0], b + noise[1]))\n",
    "\n",
    "        return measurements\n",
    "\n",
    "    def run(self,\n",
    "            commands: Iterable[Command],\n",
    "            infer: Optional[Inference] = None,\n",
    "            snapshot_every_n: Optional[int] = 0) -> SimulationResult:\n",
    "        \"\"\"Run the simulation with a sequence of commands. Optionally, execute\n",
    "        an inference algorithm along way with the simulation.\n",
    "\n",
    "        Args:\n",
    "            commands: an interable of commands.\n",
    "            infer: the inference algorithm to run the simulation with.\n",
    "            snapshot_every_n: snapshot the inference algorithm every n steps.\n",
    "                if <= 0, don't take any snapshot.\n",
    "\n",
    "        Returns:\n",
    "            SimulationResult\n",
    "        \"\"\"\n",
    "        true_poses, est_poses, snapshots = [], None, None\n",
    "\n",
    "        self.init()\n",
    "\n",
    "        i = 0\n",
    "        true_poses.append(self.state)\n",
    "        if infer:\n",
    "            est_poses, snapshots = [], []\n",
    "            infer.init(self.init_state)\n",
    "            est_poses.append(infer.estimated_pose())\n",
    "            if snapshot_every_n > 0 and i % snapshot_every_n == 0:\n",
    "                snapshots.append(copy.deepcopy(infer))\n",
    "\n",
    "        for command in commands:\n",
    "            i += 1\n",
    "            # Simulate motion\n",
    "            self.simulate_motion(command)\n",
    "            true_poses.append(self.state)\n",
    "            if infer:\n",
    "                # Simulate measurement\n",
    "                measurements = self.simulate_sensing()\n",
    "                infer.update(command, measurements)\n",
    "                est_poses.append(infer.estimated_pose())\n",
    "                if snapshot_every_n > 0 and i % snapshot_every_n == 0:\n",
    "                    snapshots.append(copy.deepcopy(infer))\n",
    "\n",
    "        return SimulationResult(self, copy.deepcopy(infer), true_poses,\n",
    "                                est_poses, snapshots)\n",
    "\n",
    "\n",
    "def drive_in_a_square_commands() -> Iterable[Command]:\n",
    "    \"\"\"Commands to simulate the robot's movement in a square.\"\"\"\n",
    "    for _ in range(4):\n",
    "        for i in range(100):\n",
    "            yield Command(.1, 0)\n",
    "        yield Command(0, np.pi / 2)\n",
    "\n",
    "\n",
    "def patrol_commands() -> Iterable[Command]:\n",
    "    \"\"\"Commands that walks back and forth horizontally.\"\"\"\n",
    "    for i in range(10):\n",
    "        yield Command(0.5, 0)\n",
    "    yield Command(0, np.pi)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_inference(sim: Simulator,\n",
    "                  commands: Sequence[Command] = tuple(\n",
    "                      drive_in_a_square_commands()),\n",
    "                  mode: str = \"localization\",\n",
    "                  num_particles: int = 100,\n",
    "                  snapshot_every_n=0) -> SimulationResult:\n",
    "    \"\"\"Utility to run inference on a simulator with a particular inference mode.\n",
    "\n",
    "    Args:\n",
    "        sim: the simulator instance to run the simulation.\n",
    "        commands: see `Simulator.run`.\n",
    "        mode: specified the mode of the inference; one of \"localization\", \"SLAM\" or \"RBSLAM\".\n",
    "            You must implement the corresponding inference algorithm in order\n",
    "            to perform inference in any mode.\n",
    "        num_particles: number of particles of the particle filter.\n",
    "        snapshot_every_n: see `Simulator.run`.\n",
    "\n",
    "    Returns:\n",
    "        A simulation result returned by `Simulator.run`.\n",
    "    \"\"\"\n",
    "\n",
    "    mode = mode.lower()\n",
    "    try:\n",
    "        if mode == \"localization\":\n",
    "            infer = Localization(\n",
    "                motion_noise_covariance=sim.motion_noise_covariance,\n",
    "                sensor_noise_covariance=sim.sensor_noise_covariance,\n",
    "                landmarks=sim.landmarks,\n",
    "                num_particles=num_particles,\n",
    "            )\n",
    "        elif mode == \"slam\":\n",
    "            infer = SLAM(\n",
    "                motion_noise_covariance=sim.motion_noise_covariance,\n",
    "                sensor_noise_covariance=sim.sensor_noise_covariance,\n",
    "                num_particles=num_particles,\n",
    "            )\n",
    "        elif mode == \"rbslam\":\n",
    "            infer = RBSLAM(\n",
    "                motion_noise_covariance=sim.motion_noise_covariance,\n",
    "                sensor_noise_covariance=sim.sensor_noise_covariance,\n",
    "                num_particles=num_particles,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecoginized inference: {mode}\")\n",
    "    except NotImplementedError:\n",
    "        raise NotImplementedError(\n",
    "            f\"You must completely implement the {infer.__class__} class to \"\n",
    "            f\"run simulation under {mode} mode\")\n",
    "\n",
    "    return sim.run(commands, infer=infer, snapshot_every_n=snapshot_every_n)\n",
    "\n",
    "\n",
    "def plot_samples(x, y, fov=((-6, -6), (20, 20)), ax=None, show=True):\n",
    "    \"\"\"Plots a list of samples of x, y coordinates as input and scatter plot the samples.\n",
    "\n",
    "    Args:\n",
    "        x: array of shape (N, ), the x-coordinates of the pose component of the particles.\n",
    "        y: array of shape (N, ), the y-coordinates of the pose component of the particles.\n",
    "        fov: a rectangular field of view. The function plots within this\n",
    "            rectanglular fov.\n",
    "        show: whether to display the plot immediately.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    ax.axis([fov[0][0], fov[1][0], fov[0][1], fov[1][1]])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_aspect('equal', 'box')\n",
    "\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.plot(x, y, 'g+')\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_trajectories(true_poses: Sequence[Pose],\n",
    "                      estimated_poses: Sequence[Pose],\n",
    "                      landmarks: Optional[Sequence[Landmark]] = None,\n",
    "                      ax: Optional['matplotlib.axes.Axes'] = None,\n",
    "                      fov=((-6, -6), (20, 20)),\n",
    "                      show=True):\n",
    "    \"\"\"Plot true and estimated poses on the same plot by overlaying them.\n",
    "    It ignores the pose.theta and only plots the location.\n",
    "\n",
    "    Args:\n",
    "        true_poses: a sequence of true poses.\n",
    "        estimated_poses: a sequence of estimated poses.\n",
    "        landmarks: optinally plot the location of true landmarks.\n",
    "        ax: an optional matplotlib Axes on which to plot the trajectories.\n",
    "        fov: a rectangular field of view. The function plots within this\n",
    "            rectanglular fov.\n",
    "        show: whether to display the plot immediately.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    ax.axis([fov[0][0], fov[1][0], fov[0][1], fov[1][1]])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_aspect('equal', 'box')\n",
    "\n",
    "    if landmarks:\n",
    "        ax.scatter([l.x for l in landmarks], [l.y for l in landmarks],\n",
    "                   marker=\"o\",\n",
    "                   color=\"black\")\n",
    "\n",
    "    ax.plot([p.x for p in true_poses], [p.y for p in true_poses],\n",
    "            color=(0, 0, 1, 0.5))\n",
    "    ax.plot([p.x for p in estimated_poses], [p.y for p in estimated_poses],\n",
    "            color=(1, 0, 0, 0.5))\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_simulation_result(result: SimulationResult,\n",
    "                           ax: Optional['matplotlib.axes.Axes'] = None,\n",
    "                           fov=((-6, -6), (20, 20)),\n",
    "                           title=None,\n",
    "                           show=True):\n",
    "    \"\"\"Plot the inference result (the state at last step of the simulation result).\n",
    "\n",
    "    Args:\n",
    "        result: result of a simulation.\n",
    "        ax: an optional matplotlin Axes to draw the result.\n",
    "        fov: see `plot_trajectories`.\n",
    "        show: whether to display the plot immediately.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    plot_trajectories(result.true_poses,\n",
    "                      result.estimated_poses,\n",
    "                      landmarks=result.sim.landmarks,\n",
    "                      ax=ax,\n",
    "                      fov=fov,\n",
    "                      show=False)\n",
    "\n",
    "    result.infer.plot_state(ax)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def render_animation(\n",
    "    result: SimulationResult,\n",
    "    fov=((-6, -6), (20, 20)),\n",
    "    save_file: Optional[str] = None,\n",
    ") -> 'matplotlib.animation.FuncAnimation':\n",
    "    \"\"\"Render simulation as a matplotlib animation.\n",
    "\n",
    "    Args:\n",
    "        result: result of a simulation.\n",
    "        fov: see `plot_trajectories`.\n",
    "        save_file: an optional string file name to save the animation.\n",
    "\n",
    "    Returns:\n",
    "        an instance of `matplotlib.animation.FuncAnimation`. You can do further\n",
    "        processing on the returned animation, display it, or save it\n",
    "        as an mp4 file.\n",
    "    \"\"\"\n",
    "    if result.snapshots is None or len(result.snapshots)==0:\n",
    "        raise ValueError(\"SimulationResult does not have any snapshots. \"\n",
    "                         \"Please re-run simulation with snapshot_every_n > 0.\")\n",
    "\n",
    "    import matplotlib.animation as animation\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    snapshot_every_n = len(result.true_poses) // len(result.snapshots)\n",
    "    true_poses = result.true_poses[::snapshot_every_n]\n",
    "    estimated_poses = result.estimated_poses[::snapshot_every_n]\n",
    "\n",
    "    def render_frame(i):\n",
    "        ax.clear()\n",
    "        ax.set_title(f\"Step {i}\")\n",
    "        plot_trajectories(true_poses[:i + 1],\n",
    "                          estimated_poses[:i + 1],\n",
    "                          landmarks=result.sim.landmarks,\n",
    "                          ax=ax,\n",
    "                          fov=fov,\n",
    "                          show=False)\n",
    "        result.snapshots[i].plot_state(ax)\n",
    "        return ax\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, render_frame, len(result.snapshots))\n",
    "    if save_file:\n",
    "        anim.save(f\"{save_file}.mp4\", fps=60)\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7caca14",
   "metadata": {
    "id": "b7caca14"
   },
   "source": [
    "# <a id=\"sampling\"></a> 1. Noise Sampling (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62120277",
   "metadata": {
    "id": "62120277"
   },
   "source": [
    "## <a id=\"warmups\"></a> 1A. Sampling Warmups (2 points)\n",
    "\n",
    "### <a id=\"warmup1\"></a> Warmup 1 (1 point)\n",
    "\n",
    "Let's make sure we know how to sample from a set of values based on their weights.\n",
    "\n",
    "Please write a function that:\n",
    "- Takes in a list of samples and associated weights.\n",
    "- Re-samples from the list of samples with replacement according the\n",
    "likelihood of each sample given by the list of weights.\n",
    "\n",
    "_Hint:_ You should use the function `numpy.random.choice`.\n",
    "\n",
    "\n",
    "For reference, our solution is **1** line(s) of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18305c",
   "metadata": {
    "id": "ab18305c"
   },
   "outputs": [],
   "source": [
    "def warmup_1(samples: np.ndarray, weights: np.ndarray,\n",
    "             nr_samples: int, seed=None) -> np.ndarray:\n",
    "    \"\"\"Draw N samples from the input list based on their weights.\n",
    "\n",
    "    Args:\n",
    "      samples: a numpy array of shape (n_samples, ), a list of samples.\n",
    "      weights: a numpy float array of shape (n_samples, ), indicating\n",
    "        the weights for individual samples.\n",
    "      nr_samples: an integer, indicating the number of samples to draw.\n",
    "      seed: optional, for reproducible results in testing\n",
    "\n",
    "    Returns:\n",
    "      resampled_samples: the return numpy array, containing nr_samples\n",
    "        samples drawn from the input list, based on the weights with replacement.\n",
    "    \"\"\"\n",
    "    # For reproducible results in testing\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134525d",
   "metadata": {
    "id": "9134525d"
   },
   "outputs": [],
   "source": [
    "# Test 1\n",
    "Grader.run_single_test_inline(TestProj3, \"test_01_warmup_1\", locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd74fa59",
   "metadata": {
    "id": "cd74fa59"
   },
   "source": [
    "### <a id=\"warmup2\"></a> Warmup 2 (1 point)\n",
    "\n",
    "We are going to be sampling from Gaussian distributions in this project. While we have not talked about continuous random variables and continuous probability densities much during the lectures, we can use the ideas from Monte Carlo inference techniques to handle continuous variables quite easily. \n",
    "\n",
    "First, let us check that we know how to sample from a multivariate Gaussian.\n",
    "Please write a function that takes in a mean vector, a covariance matrix and a integer number\n",
    "of samples and returns a list of the requested number of samples drawn from a Gaussian with the given mean and covariance.\n",
    "\n",
    "_Hint:_ You should use the function `numpy.random.multivariate_normal`.\n",
    "\n",
    "For reference, our solution is **1** line(s) of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae48fb",
   "metadata": {
    "id": "86ae48fb"
   },
   "outputs": [],
   "source": [
    "def warmup_2(mean: np.ndarray, covariance: np.ndarray,\n",
    "             num_particles: int, seed=None) -> np.ndarray:\n",
    "    \"\"\"Sample from a multi-variate Gaussian distribution.\n",
    "\n",
    "    Args:\n",
    "      mean: a numpy array of shape (N, ).\n",
    "      covariance: a numpy array of shape (N, N).\n",
    "      num_particles: an integer.\n",
    "      seed: optional, for reproducible results in testing\n",
    "\n",
    "    Returns:\n",
    "      sample: a numpy vector with length num_particles.\n",
    "    \"\"\"\n",
    "    # For reproducible results in testing\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f6398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2\n",
    "Grader.run_single_test_inline(TestProj3, \"test_02_warmup_2\", locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd8394d-38d5-46fd-8b0c-8c383eef6d88",
   "metadata": {},
   "source": [
    "## <a id=\"motion_noise\"></a> 1B. Adding Motion Noise (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b577a98",
   "metadata": {},
   "source": [
    "### <a id=\"multivariate\"></a> Experiment 1: Sampling from Multivariate Gaussian (5 points)\n",
    "\n",
    "Please generate a 2D scatter plot of 1000 samples drawn from a 2D Gaussian with `mean = [0, 0]` and `covariance = np.diag([0.05, 0.01])`, using the function you just coded: `warmup_2`. Consider using the helper function provided: `plot_samples`.\n",
    "\n",
    "<b>Submission Material 1a:</b> In your submitted pdf, please include the generated figure. Name this Figure 1a.\n",
    "\n",
    "Let's get some intuition about geometry. Please generate a second 2D scatter plot of 1000 samples drawn from a 2D Gaussian distribution. You should pick the mean and covariance so that the figure shows an ellipse with a $45$-degree angle with the x-y axes. Specifically, try to modify the mean and covariance to rotate figure 1a by 45-degrees counter-clockwise.\n",
    "\n",
    "\n",
    "<b>Submission Material 1b:</b> In your submitted pdf, please include the generated figure. Name this Figure 1b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f98ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission Material 1a and 1b\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb5c5bc",
   "metadata": {},
   "source": [
    "### <a id=\"noise\"></a> Experiment 2: Motion Noise (5 points)\n",
    "\n",
    "We have provided a simulator class for you, that simulates the noisy motion\n",
    "and sensing of the robot. Let's begin by ignoring any observations and just trusting that the robot goes where we have commanded. We'll look at the relationship between commands and actual trajectories.\n",
    "\n",
    "We have provided a `Simulator` class for you. It simulates the noisy motion and sensing of the robot. Let's begin by exploring what happens if we don't do any inference, and assume we always know where the robot is.\n",
    "\n",
    "We have provided a method `Simulator.run` that simulates the motion of the robot given a sequence of commands. For now, you may ignore the `infer` parameter. If you call this method, you will get a `SimulationResult`. Here, `SimulationResult.true_poses` holds a list of poses representing the ''true'' trajectory of the robot. You can ignore the rest of the fields in `SimulationResult` for now.\n",
    "\n",
    "Please call `run` twice, passing in `drive_in_a_square_commands()` as the commands.\n",
    "- For the first time, run on a simulator with `motion_noise_covariance=zeros((2, 2))`\n",
    "- For the second time, run on a simulator with `motion_noise_covariance=np.diag([1e-3, np.deg2rad(3)**2])`. \n",
    "\n",
    "The `drive_in_a_square_commands()` generates a sequence of commands that attempt to drive the robot in a square motion.\n",
    "However, you should see a significant difference between the trajectories without noise, which should be a perfect square, versus with noise. \n",
    "\n",
    "**Hint**: You may use the helper function `plot_trajectories` to generate the trajectory plot.\n",
    "\n",
    "<b>Submission Material 2:</b> In your submitted pdf, please include a single figure which has both experiment results overlapped on each other. Name this Figure 2.\n",
    "If we knew the noise on each step, the noise wouldn't be a problem. We could just correct for it as we steer the robot, but the problem is we don't the noise --- it's just the random perturbations added by nature. Therefore, we have to use the sensors to know where the robot is and correct for the \"drift\" in the robot motion. **That** is why we perform inference.\n",
    "\n",
    "Now we've convinced ourselves of the need for inference, let us implement the two functions we need for sampling-based inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e558ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission Material 2\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6372d32-a828-4a2b-8ef6-de55d382bf0d",
   "metadata": {},
   "source": [
    "# <a id=\"pf_localization\"></a> 2. Particle Filter Localization (48 points)\n",
    "\n",
    "Now, let’s assume that there are some landmarks (e.g. radio beacons or visible mountains in the distance) with known absolute locations. The robot can observe measurements of its relative position to these landmarks. This problem becomes an HMM, in which the hidden state is the robot’s position and orientation (called a \"pose\" for short), the noisy steering we saw above is the transition model, and the landmark measurements are the observations. We are interested in performing filtering to obtain a distribution over the robot’s pose at each time step. \n",
    "\n",
    "We could discretise the robot position, and perform HMM inference as we saw in class, but discretising the states is going to lead to a very large discrete state space that will be hard to perform inference efficiently in. If you have taken a robotics course or state estimation course elsewhere, you might be familiar with the Kalman filter as a way to estimate the state of a linear system with Gaussian noise, but as we will see, the transition dynamics of our robot are substantially non-linear and a Kalman filter will not perform well.\n",
    "\n",
    "Instead, we will use a particular form of sampling over HMMs known as the particle filter, which we discussed briefly at the very end of the HMM lecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff751fb",
   "metadata": {
    "id": "eff751fb"
   },
   "source": [
    "### Utilities\n",
    "\n",
    "Please have a look at the following utility functions for localization update by motion model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39cd8d6",
   "metadata": {
    "id": "b39cd8d6"
   },
   "outputs": [],
   "source": [
    "from functools import cached_property\n",
    "\n",
    "def multivariate_normal_logpdf(xs: np.ndarray, means: np.ndarray,\n",
    "                               covs: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Batch version of `scipy.stats.multivariate_normal.logpdf`.\n",
    "\n",
    "    Compute multivariate normal's log probability density function, with batch\n",
    "    inputs and distributions.\n",
    "    Modified from https://gregorygundersen.com/blog/2020/12/12/group-multivariate-normal-pdf/.\n",
    "\n",
    "    This function uses the following broadcasting logic:\n",
    "    - First, `means` and `covs` are broadcasted together, which determines `dist_batch`,\n",
    "        the number of individual multivariate normal distributions.\n",
    "    - Then, broadcast the rightmost dimensions of `xs` to `means`. The rest of the dimensions\n",
    "    of `xs` becomes the `input_batch` dimension.\n",
    "\n",
    "    Args:\n",
    "        xs: array of shape (...input_batch,  ...dist_batch, dist_dim)\n",
    "        means: array of shape (...dist_batch, dist_dim)\n",
    "        covs: array of shape (...dist_batch, dist_dim, dist_dim)\n",
    "\n",
    "    Returns:\n",
    "        array of shape (...input_batch, ...dist_batch, dist_dim)\n",
    "\n",
    "\n",
    "    Below we describe some uses cases, with different input shapes and the result shape.\n",
    "\n",
    "    1.  xs: (100, 2), means: (2,),  covs: (2, 2), result: (100, 2)\n",
    "        Explanation:\n",
    "            - dist_dim = 2 i.e., Gaussian is 2D\n",
    "            - `input_batch=(100,)` and `dist_batch=()`\n",
    "            - returns logpdf of 100 inputs, evaluated by the same mean and covariance.\n",
    "\n",
    "    2.  xs: (100, 2), means: (2,),  covs: (100, 2, 2), result: (100, 2)\n",
    "        Explanation:\n",
    "            - dist_dim = 2 i.e., Gaussian is 2D\n",
    "            - `input_batch=()` and `dist_batch=(100,)`\n",
    "            - returns logpdf of 100 inputs, evaluated by the same mean but with 100 different covariances.\n",
    "\n",
    "    3.  xs: (100, 10, 2), means: (2,),  covs: (100, 10, 2, 2), result: (100, 10, 2)\n",
    "        Explanation:\n",
    "            - dist_dim = 2 i.e., Gaussian is 2D\n",
    "            - `input_batch=()` and `dist_batch=(100, 10)`\n",
    "            - returns logpdf of inputs of shape (100, 10), evaluated by the same mean each with a different covariance.\n",
    "    \"\"\"\n",
    "    dist_dim = xs.shape[-1]\n",
    "    dist_batch_shape = np.broadcast_shapes(means.shape[:-1], covs.shape[:-2])\n",
    "    means = np.broadcast_to(means, dist_batch_shape + (dist_dim,))\n",
    "    covs = np.broadcast_to(covs, dist_batch_shape + (dist_dim, dist_dim))\n",
    "    xs = np.broadcast_to(xs, xs.shape[:-len(means.shape)] + means.shape)\n",
    "\n",
    "    vals, vecs = np.linalg.eigh(covs)\n",
    "    logdets = np.sum(np.log(vals), axis=-1)\n",
    "    valsinvs = 1. / vals\n",
    "    Us = vecs * np.sqrt(valsinvs)[..., np.newaxis, :]\n",
    "    devs = xs - means\n",
    "    devUs = np.einsum(\"...i,...ij->...j\", devs, Us)\n",
    "    mahas = np.sum(np.square(devUs), axis=-1)\n",
    "    log2pi = np.log(2 * np.pi)\n",
    "    out = -0.5 * (dist_dim * log2pi + mahas + logdets)\n",
    "    return out\n",
    "\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class LocalizationParticles:\n",
    "    \"\"\"A batch of particles.\"\"\"\n",
    "\n",
    "    x: np.ndarray  # shape (N, )\n",
    "    y: np.ndarray  # shape (N, )\n",
    "    theta: np.ndarray  # shape (N, )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        assert self.x.shape == self.y.shape == self.theta.shape\n",
    "        assert len(self.x.shape) == 1\n",
    "        # Always normalize the angles\n",
    "        object.__setattr__(self, \"theta\", normalize_angles(self.theta))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"The number of particles.\"\"\"\n",
    "        return self.x.shape[0]\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Localization(Inference):\n",
    "    \"\"\"Localization Inference by particle filtering.\"\"\"\n",
    "\n",
    "    # A 2x2 array for the motion covariance.\n",
    "    motion_noise_covariance: np.ndarray\n",
    "\n",
    "    # A 2x2 numpy array for the sensor noise for the\n",
    "    # measurements of range and bearing to the landmarks\n",
    "    sensor_noise_covariance: np.ndarray\n",
    "\n",
    "    # In localization, we assume that we have access to the set of landmarks.\n",
    "    landmarks: List[Landmark] = dataclasses.field(default_factory=list)\n",
    "\n",
    "    num_particles: int = 10\n",
    "\n",
    "    particles: LocalizationParticles = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.particles:\n",
    "            assert len(self.particles) == self.num_particles\n",
    "\n",
    "    @cached_property\n",
    "    def landmarks_id_map(self) -> Dict[str, Landmark]:\n",
    "        \"\"\"Map from unique landmark id to the Landmark instance.\"\"\"\n",
    "        return {l.id: l for l in self.landmarks}\n",
    "\n",
    "    def estimated_pose(self) -> Pose:\n",
    "        return Pose(np.mean(self.particles.x), np.mean(self.particles.y),\n",
    "                    circular_mean(self.particles.theta))\n",
    "\n",
    "    def estimated_landmarks(self) -> Sequence[Landmark]:\n",
    "        # we know the landmarks so no estimation required!\n",
    "        return self.landmarks\n",
    "\n",
    "    def init(self, init_state: Pose) -> None:\n",
    "        self.particles = LocalizationParticles(\n",
    "            np.full(self.num_particles, init_state.x, dtype=np.float64),\n",
    "            np.full(self.num_particles, init_state.y, dtype=np.float64),\n",
    "            np.full(self.num_particles, init_state.theta, dtype=np.float64),\n",
    "        )\n",
    "\n",
    "    def plot_state(self, ax: 'matplotlib.axes.Axes') -> None:\n",
    "        ax.quiver(\n",
    "            self.particles.x,\n",
    "            self.particles.y,\n",
    "            np.cos(self.particles.theta),\n",
    "            np.sin(self.particles.theta),\n",
    "            angles=\"xy\",\n",
    "            scale=100,\n",
    "            color=(1.0, 0, 0, 0.4),\n",
    "        )\n",
    "\n",
    "    # We incrementally implement methods below using the `implementation_for` helper\n",
    "    def motion_model(self, command: Command):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def compute_weights(self,\n",
    "                        measurements: Sequence[Measurement]) -> np.ndarray:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def update(self, command: Command, measurements: Sequence[Measurement]):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "def plot_particles(samples: LocalizationParticles, fov=((-6, -6), (20, 20))):\n",
    "    \"\"\"matplotlib helper function. It takes a list of samples as input and\n",
    "    scatter plot the samples.\n",
    "\n",
    "    Args:\n",
    "        particles: a set of particles for localization. This function only plots\n",
    "            the first two components: x and y.\n",
    "        fov: a rectangular field of view. The function plots within this\n",
    "            rectanglular fov.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.axis([fov[0][0], fov[1][0], fov[0][1], fov[1][1]])\n",
    "\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.plot(samples.x, samples.y, 'g+')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a53248",
   "metadata": {
    "id": "72a53248"
   },
   "source": [
    "## <a id=\"motion_model\"></a> 2A. Motion Model (25 points)\n",
    "\n",
    "### <a id=\"motion_imp\"></a> Motion Model Implementation (3 points)\n",
    "\n",
    "Let us now start by building a motion model for a\n",
    "simple ground robot that moves in straight lines, and performs point turns.\n",
    "\n",
    "A common motion model for such a robot assumes that the robot has a pose given\n",
    "by $[x_t, y_t, \\theta_t]$ at time $t$. The robot takes a command $[\\Delta p_t,\n",
    "\\Delta \\theta_t]$ which modifies the robot's pose according to the following:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} x_{t+1} \\\\ y_{t+1} \\\\ \\theta_{t+1} \\end{bmatrix} =\n",
    "\\begin{bmatrix} x_t + \\cos(\\theta_t) (\\Delta p_t + \\omega_t) \\\\\n",
    "y_t + \\sin(\\theta_t)(\\Delta p_t + \\omega_t) \\\\\n",
    "\\theta_t + \\Delta \\theta_t + \\nu_t\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $[\\omega_t, \\nu_t]$ is Gaussian error injected at each time\n",
    "step, distributed as $\\omega_t \\sim \\mathcal{N}(0, \\sigma^2_p)$, and\n",
    "$\\nu_t \\sim \\mathcal{N}(0, \\sigma^2_\\theta)$. The units of $\\Delta  p_t$ is in\n",
    "metres and $\\Delta \\theta_t$ in radians.\n",
    "\n",
    "Let us assume that the robot's pose at each time step is a random variable,\n",
    "represented as a set of samples.\n",
    "\n",
    "Please implement a function that updates the set of sampled poses (particles)\n",
    "drawn from prior pose random variable $\\mathbf{X}_t$\n",
    "using a control $[\\Delta p_t, \\Delta \\theta_t]$ to a set of samples drawn from the posterior $X_{t+1}$.\n",
    "\n",
    "**Note**\n",
    "In this project, we will use a helper decorator `implementation_for` to implement\n",
    "class methods outside of the class.\n",
    "The decorator `@implementation_for(Localization)` simply inserts the declared\n",
    "function as a method of the Localization class.\n",
    "\n",
    "**Hint**: Use `np.random.multivariate_normal` to generate the noise.\n",
    "\n",
    "\n",
    "For reference, our solution is **8** line(s) of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b577c08a",
   "metadata": {
    "id": "b577c08a"
   },
   "outputs": [],
   "source": [
    "@implementation_for(Localization)\n",
    "def motion_model(self: Localization, command: Command) -> None:\n",
    "    \"\"\"A motion model that simulates a one-step movement of the robot, and\n",
    "    updates to the new samples.\n",
    "\n",
    "    Args:\n",
    "        command: a Command tuple containing fields delta_p(float), the distance of the\n",
    "            movement, and delta_theta(float), the rotation of the movement.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8812eb05",
   "metadata": {
    "id": "8812eb05"
   },
   "outputs": [],
   "source": [
    "# Test 3\n",
    "Grader.run_single_test_inline(TestProj3, \"test_03_motion_model\", locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6b556b-f4d1-4c7c-96c7-4532b060c434",
   "metadata": {},
   "source": [
    "### <a id=\"exp3\"></a> Experiment 3: Noisy Motion (5 points)\n",
    "\n",
    "Now that you have implemented `motion_model`, let's play with the noise parameters. Let's first use the motion parameters of `motion_noise_covariance=np.eye(2)`:\n",
    "- Initialize your particle filter using the default parameters (but pass in the above motion noise parameter and use 1000 particles), \n",
    "and step through the motion model twice. \n",
    "- Use a Command of $\\Delta_p = 1m$ and $\\Delta_\\theta = 0$ for both times.\n",
    "- Please generate plots of the $[x, y]$ component of the particles after the first and\n",
    "second motions (two separate plots).\n",
    "\n",
    "This is a pretty noisy motion! You should see the particles much more spread out than they were at the start. Why is the distribution long and skinny after one motion and then really spread out after the second motion?\n",
    "\n",
    "\n",
    "<b>Submission Material 3:</b> In your submitted pdf, please include the generated figures. Name them Figure 3a and 3b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcce443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission Material 3a and 3b\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7d8b55",
   "metadata": {},
   "source": [
    "### <a id=\"exp4\"></a> Experiment 4: Less Noisy Motion (5 points)\n",
    "\n",
    "Now let's try reducing the noise parameters. Please perform Experiment 3 again, but set \n",
    "`motion_noise_covariance=np.diag([1e-2, np.deg2rad(.5)**2])`.\n",
    "Please generate two plots same as in experiment 3. \n",
    "The particle set should be much more compact than before and track the motion you commanded.\n",
    "\n",
    "<b>Submission Material 4:</b> In your submitted pdf, please include the generated figures.\n",
    "Name them Figure 4a and 4b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfabce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission Material 4a and 4b\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e662edbc",
   "metadata": {},
   "source": [
    "### <a id=\"exp5\"></a> Experiment 5: Finer Motion (5 points)\n",
    "\n",
    "For the two experiments above, we're taking pretty big motions, commanding a meter at a time. A mobile robot would generally send commands and get measurements at a much higher frequency. For example, the robot sends commands at 10 Hz and travels at 1 m/s. Please perform an experiment that moves the robot the same 2m forward but in .1 m increments. Please upload a plot of the particles' $[x, y]$ component after 2 m.\n",
    "\n",
    "In this question, please use the same reduced noise parameters: `motion_noise_covariance=np.diag([1e-2, np.deg2rad(.5)**2])` as in the previous experiment.\n",
    "\n",
    "<b>Submission Material 5:</b> In your submitted pdf, please include the generated figure. Name this Figure 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a730b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission Material 5\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f27c08e",
   "metadata": {},
   "source": [
    "### <a id=\"exp6\"></a> Experiment 6: Adjusting Noise for Finer Motion (5 points)\n",
    "\n",
    "Even though all we did is changed how often we sent a command to the robot, the sample set is much more spread out. You might think that the uncertainty in the robot's position is independent of things like control frequency, but\n",
    "this plot should show you that they aren't. When we adjust the control frequency, we also have to adjust the model parameters.\n",
    "\n",
    "Let's set `motion_noise_covariance=np.diag([1e-3, np.deg2rad(.5)**2])`. \n",
    "In your submitted pdf, please include two plots of the $[x, y]$ component of the 1000 particles after 2m. \n",
    "\n",
    "The particle set should be much more compact again, and track the motion you commanded.\n",
    "\n",
    "<b>Submission Material 6:</b> In your submitted pdf, please include the generated figures.\n",
    "Name them Figure 6a and 6b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e47e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission Material 6a and 6b\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efb774d",
   "metadata": {},
   "source": [
    "### <a id=\"exp7\"></a> Experiment 7: Unbalanced Noise (5 points)\n",
    "\n",
    "What happens when our motion model has worse rotation noise than translation noise? \n",
    "Let's set `motion_noise_covariance=np.diag([1e-3, np.deg2rad(30)**2])`.\n",
    "Please generate plots of the $[x, y]$ component of the samples after 1m, 2m and 3m of motion made in 1m increments. You should see the samples are tightly contained, but are in a curved shape. This shape is a result of the\n",
    "non-linear relationship between orientation and position, and is one of the reasons we often use sampling for localization, rather than a parametric form such as a Gaussian.\n",
    "\n",
    "<b>Submission Material 7:</b> In your submitted pdf, please include the generated figures.\n",
    "Name them Figure 7a, 7b, and 7c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06149c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission Material 7a, 7b, and 7c\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a816fde",
   "metadata": {
    "id": "6a816fde"
   },
   "source": [
    "## <a id=\"localization_importance\"></a> 2B. Localization: Computing the Importance Weights (10 points)\n",
    "\n",
    "\n",
    "Let us now add in a measurement model.\n",
    "Let us assume that we have a set of landmarks given by `grid_of_landmarks()` (i.e., the default set of landmarks of a Simulator).\n",
    "The robot is equipped with a sensor that can measure the range and\n",
    "relative bearing $[r, b]$ from the robot's location to each of these landmarks. If the\n",
    "robot's pose is $(x, y, \\theta)$ and the landmark position is $(l_x, l_y)$,\n",
    "then range is just the Euclidean distance $$r = \\sqrt{(l_x - x)^2 + (l_y\n",
    "-y)^2}$$\n",
    "and the bearing is the angle to the landmark in the robot's body frame (hence\n",
    "relative bearing), $$b = \\texttt{atan2}(l_y - y, l_x - x) - \\theta.$$  Each of\n",
    "these measurements is corrupted with noise $[q_r, q_b]$ distributed according\n",
    "to $q_r \\sim \\mathcal{N}(0, \\sigma^2_r)$ and $q_b \\sim \\mathcal{N}(0,\n",
    "\\sigma^2_b)$.\n",
    "\n",
    "Please take a look at our implementation in `simulator.simulate_sensing` and\n",
    "understand how the values are simulated.\n",
    "\n",
    "Now the problem is that for a real robot, even if you know this is the model\n",
    "that generates the measurements, you can't know the noise that nature applied. (That would be omniscience!)\n",
    "What we can do is work out how likely each measurement is. More precisely, given a set of measurements, we can use\n",
    "this model to compute the importance weights of a set of samples of the robot\n",
    "pose. \n",
    "\n",
    "In particular, to compute the importance weight of a particle:\n",
    "- Compute the _predicted measurements_ from the current state of the robot's pose and the landmark locations.\n",
    "- Compute the errors $\\mathit{err}$ between the predicted and true measurements.\n",
    "- Compute the likelihood of the $\\mathit{err}$ as the unnormalized importance weights.\n",
    "The likelihood of the error is the evaluation of the probability density function (PDF) of the two-dimensional Gaussian distribution with covariance `sensor_noise_covariance` at $\\mathit{err}$.\n",
    "- Finally, normalize the weights so that they sum to one.\n",
    "\n",
    "Please implement a function that takes a set of samples and measurements and\n",
    "returns the importance weights of the samples.\n",
    "\n",
    "There are a few technicalities during this process:\n",
    "- We highly recommend you normalize **all the rotational values** (in radians) to the interval $[-\\pi, \\pi]$ (see function `normalize_angles`).\n",
    "Notably, the rotational component of the $\\mathit{err}$, which we denote as $\\mathit{err}_\\theta$, is a rotational\n",
    "value in radians. Therefore, theoretically, the likelihood of $\\mathit{err}_\\theta$ should have been\n",
    "the evaluation of the PDF of a [wrapped Gaussian distribution](https://en.wikipedia.org/wiki/Wrapped_normal_distribution).\n",
    "In other words, to evaluate the likelihood of\n",
    "$\\mathit{err}_\\theta$, we should have taken the sum of the Gaussian PDFs at the points\n",
    "$\\mathit{err}_\\theta + 2k\\pi$ for all $k \\in \\mathbb{Z}$.\n",
    "Nonetheless, since our sensor noise is relatively small, we expect only the single point at $k=0$\n",
    "$\\mathit{err}_\\theta \\in [-\\pi, \\pi]$ to have a relatively large value, and all other\n",
    "points to have close-to-zero values. Therefore, we may use the Gaussian distribution as a\n",
    "good approximation to the true wrapped Gaussian distribution.\n",
    "- The likelihood for the particles can become really small. For numerical stability,\n",
    "you will want to compute the _log-likelihood_ instead of the likelihood.\n",
    "To that end, you may:\n",
    "    - Use the utility `multivariate_normal_logpdf` that we provided you to evaluate the log PDF.\n",
    "    - Take the sum (instead of multiplications) of the log-likelihoods to compute the unnormalized log-weight of each particle.\n",
    "    - Normalize the log-weights. You should use [`scipy.special.logsumexp`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.logsumexp.html) to evaluate\n",
    "the log-sum of the weights. In short, The `logsumexp` function calculates the following expression in a more\n",
    "numerically stable way:\n",
    "$$\n",
    "\\texttt{logsumexp}(x_1, ... x_n) = \\log \\left( \\sum_{i=1}^{n} \\exp(x_i) \\right).\n",
    "$$ See <a href=\"https://gregorygundersen.com/blog/2020/02/09/log-sum-exp/\" target=\"_blank\">this blog</a> for a more detailed description of this function.\n",
    "    - Use `numpy.exp` to undo the logarithm from the log-weights and return the weights.\n",
    "\n",
    "\n",
    "For reference, our solution is **29** line(s) of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84307336",
   "metadata": {
    "id": "84307336"
   },
   "outputs": [],
   "source": [
    "@implementation_for(Localization)\n",
    "def compute_weights(self: Localization,\n",
    "                    measurements: Sequence[Measurement]) -> np.ndarray:\n",
    "    \"\"\"Compute the importance weights of the samples, based on the new\n",
    "    measurement.\n",
    "\n",
    "    Args:\n",
    "        measurements: a sequence of measurements made by the robot.\n",
    "\n",
    "    Returns:\n",
    "        weights: a numpy array of importance weights, normalized to 1.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2444b150",
   "metadata": {
    "id": "2444b150"
   },
   "outputs": [],
   "source": [
    "# Test 4\n",
    "Grader.run_single_test_inline(TestProj3, \"test_04_importance_weights\", locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037ac65f",
   "metadata": {
    "id": "037ac65f"
   },
   "source": [
    "## <a id=\"localization_pfupdate\"></a> 2C. Localization: Particle Filter Update (10 points)\n",
    "\n",
    "What we want you to do is to write a method `update` that takes in a\n",
    "set of samples, the most recent command, and the most recent measurements, and then:\n",
    "  * Use the motion_model method to update the sample based on the command\n",
    "  * Use compute_weights to compute the sample weights from the\n",
    "measurement,\n",
    "  * Resample a new set of samples,\n",
    "  * Blur the samples by applying noise drawn from a zero-mean Gaussian with\n",
    "covariance equal to `np.diag([1e-3, 1e-3, np.deg2rad(1)**2])`. (You'll need to\n",
    "recall from lecture why we do this blurring --- if you have machine learning\n",
    "background, it's a form of regularization, but you don't need to know about\n",
    "regularization to understand why this is important.)\n",
    "\n",
    "\n",
    "For reference, our solution is **12** line(s) of code.\n",
    "\n",
    "In addition to all the utilities defined at the top of this notebook, the following functions are available: `compute_weights`, `motion_model`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b60c7cc",
   "metadata": {
    "id": "2b60c7cc"
   },
   "outputs": [],
   "source": [
    "@implementation_for(Localization)\n",
    "def update(self: Localization, command: Command,\n",
    "           measurements: Sequence[Measurement]) -> None:\n",
    "    \"\"\"Update the samples, based on the command and the new measurement.\n",
    "\n",
    "    Args:\n",
    "        command: a Command tuple containing fields delta_p(float), the distance of the\n",
    "        movement, and delta_theta(float), the rotation of the movement.\n",
    "        measurement: a measurement vector. The measurement is computed by\n",
    "            `simulator.simulate_sensing` function.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5507784",
   "metadata": {
    "id": "c5507784"
   },
   "outputs": [],
   "source": [
    "# Test 5\n",
    "Grader.run_single_test_inline(TestProj3, \"test_05_particle_filter\", locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbea062d-c62d-4d13-8907-1b62c7d7dad6",
   "metadata": {},
   "source": [
    "## <a id=\"evaluating_pf_localization\"></a> Evaluating Particle Filter-based Localization (5 points)\n",
    "\n",
    "\n",
    "### <a id=\"exp8\"></a> Experiment 8: Running the Localization Particle Filter (5 points)\n",
    "\n",
    "Let's visualize our particle filter.\n",
    "\n",
    "Please generate a trajectory plot and an animation of the robot carrying out the \n",
    "localization inference. \n",
    "In particular:\n",
    "- Use the default Simulator parameters (i.e. simply use `Simulator()`)\n",
    "- Run localization with `num_particles=100`.\n",
    "- Plot (and also animate) the obtained results.\n",
    "\n",
    "If everything is working, your estimated and ground truth trajectories should match up closely, but not exactly. \n",
    "(You should be able to inspect the estimated and ground truth trajectories manually, and see that they differ by some small errors at each step.)\n",
    "\n",
    "\n",
    "Here are some handy functions for your experiments:\n",
    "- `run_inference`: It takes in a simulator instance and runs\n",
    "inference in a particular mode --- for this question, you should pass in \n",
    "the \"localization\" mode. It returns a `SimulationResult` instance. \n",
    "- `plot_simulation_result`: It visualizes a `SimulationResult`.\n",
    "- `render_animation`: It creates an animated visualization of a `SimulationResult`.\n",
    "\n",
    "<b>Submission Material 8:</b> \n",
    "In your submitted pdf, please include the generated figure. Name this Figure 8.\n",
    "Additionally include the generated animation. Name this 'localization.mp4'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304cf2e9-7ccc-455e-8932-18cc6c32a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission Material 8\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ba4319",
   "metadata": {
    "id": "26ba4319"
   },
   "source": [
    "# <a id=\"pf_slam\"></a>3. Particle Filter SLAM (40 points)\n",
    "\n",
    "Now, what if we don't know the landmark positions in advance?  \n",
    "If the robot knew its locations exactly, it could use its observations of the landmarks to build a map of the \n",
    "landmarks' locations in absolute coordinates. But the robot is as lost as it was before --- what can we do?\n",
    "This problem is known as *simultaneous localization and mapping* (SLAM) --- we need to estimate both the robot's pose *and* the map (i.e., the positions of the landmarks).\n",
    "\n",
    "In this section, we will use the same algorithm from last section, the particle filter, to approach the SLAM problem.\n",
    "Recall each particle in the localization problem only contains a robot's pose.\n",
    "In the SLAM case, each particle will now contain a complete \"possible world\" --- made up of a robot pose and a location of each landmark that is known by to the robot so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65087d26",
   "metadata": {
    "id": "65087d26"
   },
   "source": [
    "### Utilities\n",
    "\n",
    "Please have a look at the following utility functions for Particle Filter SLAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309440bd",
   "metadata": {
    "id": "309440bd"
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass(frozen=True)\n",
    "class SLAMParticles:\n",
    "    \"\"\"A batch of samples for SLAM.\"\"\"\n",
    "    x: np.ndarray  # shape: (num_particles, )\n",
    "    y: np.ndarray  # shape: (num_particles, )\n",
    "    theta: np.ndarray  # shape: (num_particles, )\n",
    "\n",
    "    # Mapping from landmark_id to the index of that landmark in `landmarks_loc`\n",
    "    landmarks_id_to_idx: Dict[str, int]\n",
    "\n",
    "    landmarks_loc: np.ndarray  # shape (num_particles, num_landmarks, 2)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        assert self.x.shape == self.y.shape == self.theta.shape, \"shape must match\"\n",
    "        assert self.x.shape[0] == self.landmarks_loc.shape[\n",
    "            0], \"shape must match\"\n",
    "        assert self.landmarks_loc.shape[1] == len(\n",
    "            self.landmarks_id_to_idx), \"shape must match\"\n",
    "        object.__setattr__(self, \"theta\", normalize_angles(self.theta))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"The number of samples.\"\"\"\n",
    "        return self.x.shape[0]\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class SLAM(Inference):\n",
    "\n",
    "    # A 2x2 array for the motion covariance.\n",
    "    motion_noise_covariance: np.ndarray\n",
    "\n",
    "    # A 2x2 numpy array for the sensor noise for the\n",
    "    # measurements of range and bearing to the landmarks\n",
    "    sensor_noise_covariance: np.ndarray\n",
    "\n",
    "    # A 2x2 array for the covariance when initializing new landmarks\n",
    "    new_landmarks_init_covariance: np.ndarray = np.eye(2) * 10\n",
    "\n",
    "    num_particles: int = 10\n",
    "\n",
    "    particles: SLAMParticles = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.particles:\n",
    "            assert len(self.particles) == self.num_particles\n",
    "\n",
    "    def estimated_pose(self) -> Pose:\n",
    "        return Pose(np.mean(self.particles.x), np.mean(self.particles.y),\n",
    "                    circular_mean(self.particles.theta))\n",
    "\n",
    "    def estimated_landmarks(self) -> Sequence[Landmark]:\n",
    "        landmarks_loc = np.mean(self.particles.landmarks_loc, axis=0)\n",
    "        idx_to_id = {\n",
    "            idx: id for id, idx in self.particles.landmarks_id_to_idx.items()\n",
    "        }\n",
    "        return [\n",
    "            Landmark(idx_to_id[i], *loc) for i, loc in enumerate(landmarks_loc)\n",
    "        ]\n",
    "\n",
    "    def init(self, init_state: Pose) -> None:\n",
    "        self.particles = SLAMParticles(\n",
    "            np.full(self.num_particles, init_state.x, dtype=np.float64),\n",
    "            np.full(self.num_particles, init_state.y, dtype=np.float64),\n",
    "            np.full(self.num_particles, init_state.theta, dtype=np.float64),\n",
    "            {},\n",
    "            np.empty((self.num_particles, 0, 2), dtype=np.float64),\n",
    "        )\n",
    "\n",
    "    def get_measured_landmarks_idx(\n",
    "            self, measurements: Sequence[Measurement]) -> np.ndarray:\n",
    "        \"\"\"Given a sequence of measurements, find the indices of each of the l\n",
    "        andmark in `self.particles`.\n",
    "\n",
    "        Args:\n",
    "            measurements: a sequence of measures. This function assumes that all\n",
    "            landmarks in this input sequence of measurements are already tracked\n",
    "            (i.e., using `self.add_new_landmarks`).\n",
    "        \"\"\"\n",
    "        return np.array(\n",
    "            [\n",
    "                self.particles.landmarks_id_to_idx[m.landmark_id]\n",
    "                for m in measurements\n",
    "            ],\n",
    "            dtype=int,\n",
    "        )\n",
    "\n",
    "    def plot_state(self, ax: 'matplotlib.axes.Axes') -> None:\n",
    "        import matplotlib.pyplot as plt\n",
    "        cmap = plt.get_cmap('viridis')\n",
    "\n",
    "        ax.quiver(\n",
    "            self.particles.x,\n",
    "            self.particles.y,\n",
    "            np.cos(self.particles.theta),\n",
    "            np.sin(self.particles.theta),\n",
    "            angles=\"xy\",\n",
    "            scale=100,\n",
    "            color=(1.0, 0, 0, 0.1),\n",
    "        )\n",
    "\n",
    "        idx_to_id = {\n",
    "            idx: id for id, idx in self.particles.landmarks_id_to_idx.items()\n",
    "        }\n",
    "        landmark_idx_to_color_code = np.array([\n",
    "            float(hash(idx_to_id[idx]) % 256) / 256\n",
    "            for idx in range(self.particles.landmarks_loc.shape[1])\n",
    "        ])\n",
    "\n",
    "        ax.scatter(self.particles.landmarks_loc[..., 0].flatten(),\n",
    "                   self.particles.landmarks_loc[..., 1].flatten(),\n",
    "                   marker=\"x\",\n",
    "                   c=np.broadcast_to(\n",
    "                       landmark_idx_to_color_code,\n",
    "                       self.particles.landmarks_loc.shape[:-1]).flatten(),\n",
    "                   cmap=cmap)\n",
    "\n",
    "    # We will incrementally implement methods below using the `implementation_for`\n",
    "    # helper\n",
    "    def motion_model(self, command: Command) -> None:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def add_new_landmarks(self, measurements: Sequence[Measurement]) -> None:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def compute_weights(self,\n",
    "                        measurements: Sequence[Measurement]) -> np.ndarray:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def update(self, command: Command,\n",
    "               measurements: Sequence[Measurement]) -> None:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc05bd",
   "metadata": {
    "id": "f9fc05bd"
   },
   "source": [
    "## <a id=\"slam_motion_model\"></a> 3A. SLAM: Update by Motion Model (5 points)\n",
    "\n",
    "Please implement a function that takes in a control command $[\\Delta p_t, \\Delta \\theta_t]$\n",
    "and updates the particles by drawing from the posterior $X_{t+1}$ using the motion model.\n",
    "\n",
    "This function behaves the same as `Localization.motion_model` for the pose\n",
    "components of the particles, and simply keeps the landmarks components\n",
    "(`SLAMParticles.landmarks_id_to_idx` and `SLAMParticles.landmarks_loc`)\n",
    "of the particles the same.\n",
    "\n",
    "**Hint**:\n",
    "Please take a look at the fields of the `SLAMParticles` class.\n",
    "Note that `landmarks_id_to_idx` stores all the landmarks the robot has encountered so far.\n",
    "It is a mapping from a landmark identifier (a string) to an index (an integer).\n",
    "You can use the integer index to index into the `landmarks_loc` array.\n",
    "In particular, `landmarks_loc` is an array of shape `(num_particles, len(landmarks_id_to_idx), 2)`.\n",
    "Therefore, to access the coordinate of the landmark with the identifier `\"Stata\"` contained\n",
    "in the $i$-th particle:\n",
    "```python\n",
    "# assert isinstance(particles, SLAMParticles)\n",
    "loc = particles.landmarks_loc[i, particles.landmarks_id_to_idx[\"Stata\"]]\n",
    "```\n",
    "\n",
    "\n",
    "For reference, our solution is **11** line(s) of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc73a2b",
   "metadata": {
    "id": "1fc73a2b"
   },
   "outputs": [],
   "source": [
    "@implementation_for(SLAM)\n",
    "def motion_model(self: SLAM, command: Command) -> None:\n",
    "    \"\"\"A motion model that simulates a one-step movement of the robot and updates the particles.\n",
    "\n",
    "    Args:\n",
    "        command: a Command tuple containing fields delta_p(float), the distance of the\n",
    "            movement, and delta_theta(float), the rotation of the movement.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b84876",
   "metadata": {
    "id": "d3b84876"
   },
   "outputs": [],
   "source": [
    "# Test 6\n",
    "Grader.run_single_test_inline(TestProj3, \"test_06_motion_model_update\", locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f0e8c5",
   "metadata": {
    "id": "59f0e8c5"
   },
   "source": [
    "## <a id=\"slam_tracking\"></a>3B. SLAM: Tracking New Landmarks (10 points)\n",
    "\n",
    "Since our robot might have limited sensing range (see the parameter `Simulator.max_sensing_range`),\n",
    "the robot is not aware of all the possible landmarks out there in the world.\n",
    "Therefore, we have to match newly observed landmarks to ones we have seen before,\n",
    "and add landmarks that we are seeing for the first time to our map.  \n",
    "In some situations, the matching is difficult, but for our purposes,\n",
    "we’ll assume that the landmarks are uniquely identifiable, so we know exactly\n",
    "which ones we are observing on each step.\n",
    "\n",
    "One way to handle missing data due to sensing range is to explicitly model the\n",
    "sensing range in our probabilistic model of the sensors.\n",
    "However, this approach would induce a difficult inference problem.  \n",
    "Instead, we will take the approach of treating the missingness as uninformative.\n",
    "In particular, we will consider sensor data within-range as observed variable,\n",
    "and sensor data out-of-range as unobserved variables.\n",
    "When we see a new landmark for the first time, we will assume that our belief\n",
    "about the location of that landmark has a mean equal to that first observed location\n",
    "and a standard variance (new_landmarks_init_covariance).\n",
    "Note, though, that in practice it might be more common to wait until we have gotten\n",
    "a few observations and use their mean as the mean of the distribution for\n",
    "initializing our particles.\n",
    "\n",
    "Please implement a function that takes a set of measurements and updates the\n",
    "particles to include potentially new landmarks that are not yet tracked by the\n",
    "particles.\n",
    "\n",
    "Below we give a description for this procedure:\n",
    "\n",
    "- Filter the input measurements to contain only measurements to the new (untracked)\n",
    "landmarks.\n",
    "- For each new landmark measurement and each particle:\n",
    "    - Find the predicted location using the robot's pose of that particle and the landmark's measurement.\n",
    "    - Add a Gaussian noise of covariance `self.new_landmarks_init_covariance` to this predicted location.\n",
    "    - This noisy location becomes the landmark's location in the current particle.\n",
    "- Update `self.particles.landmarks_id_to_idx` to maintain the invariance that it\n",
    "holds a mapping from each tracked unique landmark identifier to the index of\n",
    "that landmark in `self.particles.landmarks_loc`.\n",
    "\n",
    "For reference, our solution is **24** line(s) of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e7dadf",
   "metadata": {
    "id": "74e7dadf"
   },
   "outputs": [],
   "source": [
    "@implementation_for(SLAM)\n",
    "def add_new_landmarks(self: SLAM, measurements: Sequence[Measurement]) -> None:\n",
    "    \"\"\"Add new landmarks into all particles to track them.\n",
    "\n",
    "    Args:\n",
    "        measurements: the measurements. This function will add only the new\n",
    "        landmarks in these measurements (i.e., those that had not been added\n",
    "        before).\n",
    "    \"\"\"\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152141f1",
   "metadata": {
    "id": "152141f1"
   },
   "outputs": [],
   "source": [
    "# Test 7\n",
    "Grader.run_single_test_inline(TestProj3, \"test_07_new_landmarks\", locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5bf246",
   "metadata": {
    "id": "dd5bf246"
   },
   "source": [
    "## <a id=\"slam_importance\"></a>3C. SLAM: Computing the Importance Weight (10 points)\n",
    "\n",
    "Please implement the `SLAM.compute_weights` function that takes a\n",
    "sequence of measurements and returns the importance weights of the particles.\n",
    "\n",
    "This function is similar to `Localization.compute_weights`, except that it takes\n",
    "into account the landmarks location tracked in the particles.\n",
    "\n",
    "\n",
    "For reference, our solution is **17** line(s) of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84e7780",
   "metadata": {
    "id": "a84e7780"
   },
   "outputs": [],
   "source": [
    "@implementation_for(SLAM)\n",
    "def compute_weights(self: SLAM,\n",
    "                    measurements: Sequence[Measurement]) -> np.ndarray:\n",
    "    \"\"\"Compute the importance weights of the particles, based on the measurement.\n",
    "\n",
    "    Args:\n",
    "        measurements: a sequence of measurements made by the robot.\n",
    "\n",
    "    Returns:\n",
    "        weights: a numpy array of importance weights, normalized to 1.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661ab99",
   "metadata": {
    "id": "9661ab99"
   },
   "source": [
    "Run the following tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a81217",
   "metadata": {
    "id": "44a81217"
   },
   "outputs": [],
   "source": [
    "# Test 8\n",
    "Grader.run_single_test_inline(TestProj3, \"test_08_slam_weights\", locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf1721e",
   "metadata": {
    "id": "ccf1721e"
   },
   "source": [
    "## <a id=\"slam_pf_update\"></a>3D. SLAM: Particle Filter Update (5 points)\n",
    "\n",
    "Please implement the update step of SLAM.\n",
    "\n",
    "The procedure is similar to `Localization.update`, except that it does an additional `add_new_landmarks`\n",
    "step after forward updating with the `motion_model` and before `compute_weights`.\n",
    "\n",
    "\n",
    "For reference, our solution is **16** line(s) of code.\n",
    "\n",
    "In addition to all the utilities defined at the top of this notebook, the following functions are available in this question environment: `add_new_landmarks`, `compute_weights`, `motion_model`. You may not need to use all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cc3e65",
   "metadata": {
    "id": "b6cc3e65"
   },
   "outputs": [],
   "source": [
    "@implementation_for(SLAM)\n",
    "def update(self: SLAM, command: Command,\n",
    "           measurements: Sequence[Measurement]) -> None:\n",
    "    \"\"\"Update the particles, based on the command and measurements.\n",
    "\n",
    "    Args:\n",
    "        command: a Command tuple containing fields delta_p(float), the distance of the\n",
    "        movement, and delta_theta(float), the rotation of the movement.\n",
    "        measurement: a measurement vector. The measurement is computed by\n",
    "            `simulator.simulate_sensing` function.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012fb0d7",
   "metadata": {
    "id": "012fb0d7"
   },
   "source": [
    "Run the following tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c6156",
   "metadata": {
    "id": "277c6156"
   },
   "outputs": [],
   "source": [
    "# Test 9\n",
    "Grader.run_single_test_inline(TestProj3, \"test_09_slam_particles\", locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1deb6c-2dbd-4519-a231-342d0369b025",
   "metadata": {},
   "source": [
    "## <a id=\"evaluating_pf_slam\"></a> Evaluating Particle Filter-based SLAM (10 points)\n",
    "\n",
    "### <a id=\"exp9\"></a> Experiment 9: Running the SLAM Particle Filter (5 points)\n",
    "\n",
    "Let's visualize our SLAM particle filter.\n",
    "\n",
    "Please generate an animation of the robot carrying out inference in the default Simulator. \n",
    "\n",
    "In particular:\n",
    "\n",
    "- Run SLAM in the default Simulator with `num_particles=1000` and `max_sensing_range=6`. \n",
    "- Visualize the inference using `render_animation`.\n",
    "\n",
    "<b>Submission Material 9:</b> \n",
    "In your submission, please include the generated animation. Name the file 'slam.mp4'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission Material 9\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72b0158",
   "metadata": {},
   "source": [
    "### <a id=\"exp10\"></a> Experiment 10: More Fun with the SLAM Particle Filter (5 points)\n",
    "\n",
    "Let's further visualize our SLAM particle filter for more settings.\n",
    "\n",
    "Please generate plots of the robot carrying out inference in the default Simulator. \n",
    "\n",
    "In particular:\n",
    "\n",
    "- Run SLAM in the default Simulator, for all combinations of these parameters:\n",
    "    - `num_particles` in `[100, 1000]`\n",
    "    - `max_sensing_range` in `[6, np.inf]`\n",
    "- Use `plot_simulation_result` to plot the obtained estimated trajectory and landmarks for each setting. \n",
    "\n",
    "<b>Submission Material 10:</b> \n",
    "In your submitted pdf, please include the generated figures.\n",
    "For each plot, indicate its setting (i.e., the parameter values) in the caption or title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556970c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission Material 10\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21852c4-cab2-449c-8d06-32fb365b191e",
   "metadata": {},
   "source": [
    "## Final Submission\n",
    "Your final submission to gradescope should include the following files:\n",
    "\n",
    "- project02_release.ipynb: Your completed notebook with output from running each cell. Make sure to save. \n",
    "- localization.mp4: The animation of the successful run of the localizing robot. \n",
    "- slam.mp4: The animation of the successful run of the mapping robot. \n",
    "- A PDF of the results of the experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b56aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all tests\n",
    "Grader.grade_output([TestProj3], [locals()], \"results.json\")\n",
    "Grader.print_test_results(\"results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d738d173",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "#   SAVE YOUR NOTEBOOK BEFORE SUBMITTING!!!   #\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you save the notebook before running this cell so that the most updated version is zipped!\n",
    "Grader.prepare_submission(\"Project03_release\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2013bb12-d4d8-4772-bf36-54212d3271c0",
   "metadata": {},
   "source": [
    "## Feedback\n",
    "\n",
    "If you have any feedback for us, please complete [this form](https://forms.gle/QR5EJid3JHyCCRs66)!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "mp02.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
