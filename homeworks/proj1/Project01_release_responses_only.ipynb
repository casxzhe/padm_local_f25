{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77b6fc67-c474-4e25-9382-a8769d43877e",
   "metadata": {},
   "source": [
    "## <a id=\"contributors\"></a>0. Credit for Contributors\n",
    "\n",
    "List the various students, lecture notes, or online resouces that helped you complete this project:\n",
    "\n",
    "Ex: I worked with Bob on the inference.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4fa58b",
   "metadata": {},
   "source": [
    "No other contributors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383a1881-2ffa-48f9-bd14-7116f235efd1",
   "metadata": {},
   "source": [
    "**First-order Logic:** In what way would having access to first-order logic have been helpful in this problem?\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baac1ad-544c-478f-b9dc-d460044e40f1",
   "metadata": {},
   "source": [
    "First-order logic would allow rules t be expressed compactly using quantifiers instead of grounding out every possible cell combination. e.g. could write \" for all x,y: Smoke(x,y) → exists adjacent cell with Fire\" once, rather than creating separate propositional variables and constraints for each grid location, making the representation more natural + scalable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c8d742-57a7-479a-b40d-7ed0a19d25d6",
   "metadata": {},
   "source": [
    "**Heuristics:** The heuristics used in `pyperplan` are *domain-independent*; we can use them for Search and Rescue, for blocks world, etc.  An alternative strategy would be to hand-specify a *domain-specific* heuristic. What would a good domain-specific heuristic for search and rescue look like?\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9858dd-f65e-447d-a0fd-ef826ca078b8",
   "metadata": {},
   "source": [
    "A good domain-specific heuristic would estimate the sum of Manhattan distances from the robot to each unpicked person plus the distances from each person to the hospital, accounting for the fact that the robot can only carry one person at a time. Could also be enhanced by adding penalties for paths near fire/smoke and along the same vein, bonuses for efficiently sequencing nearby people, which captures problem structure better than general domain-independent heuristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559529cf-3b43-46f5-b118-29aea1d36d48",
   "metadata": {},
   "source": [
    "**Look first:** We do one observation before choosing our first action.  Give an example scenario where omitting this step and using the reckless or two-phase planner would make an error.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b71fad3-18aa-4ebf-b688-4298fae0ca25",
   "metadata": {},
   "source": [
    "If the robot starts at (0,0) with fire immediately adjacent at (1,0), the reckless planner without an initial observation would optimistically plan to move down into that square and fail immediately. The initial observation reveals this fire, allowing the planner to route around it from the start."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb7f52f-8db0-4907-9401-ac5d0d7ba684",
   "metadata": {},
   "source": [
    "**Replanning:**  Currently, for the policies in 3.3-3.4, we replan whenever executing the next step would be unsafe. That might not be the best replanning strategy. Describe another strategy, give a concrete example of where it would do something differently than the current strategy,\n",
    "and say what the general trade-offs would be between that one and the current one.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7a1f86-ee7b-4777-9f91-795b88b7c725",
   "metadata": {},
   "source": [
    "An alternative strategy could be \"predictive replanning\", i.e. replan whenever fire is discovered anywhere on the current planned path, not just at the immediate next step. This would avoid wasted moves toward destinations we'll need to detour around anyway, trading more frequent replanning costs for potentially fewer total execution steps. This is better when execution is expensive, worse when planning is expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7516b84-4687-4b77-a493-82c4a2fff8ce",
   "metadata": {},
   "source": [
    "**Planner Analysis:** Using the `test_policy` function, run your policies in the following three scenarios, specifically run:\n",
    "* The safe-and-smart planner\n",
    "* The reckless planner\n",
    "* The belief-space (looks before it leaps) planner\n",
    "    with the scenarios defined as:\n",
    "    * belief_map = P1_B0, true_map = P1_G0\n",
    "    * belief_map = P1_B1, true_map = P1_G0\n",
    "    * belief_map = P2_B1, true_map = P2_G0\n",
    "\n",
    "(These belief maps and true maps are all defined in the utility code at the top of this notebook.) \n",
    "\n",
    "In your answer below, don't count \"look\" as a step.\n",
    "* How many steps does each policy take to solve each problem?\n",
    "* Which method takes the fewest steps summed over all three problems?\n",
    "* Which one would you choose if planning is very expensive compared to execution?\n",
    "* Which one would you choose if execution is very expensive compared to planning? (In this case, what additional modifications might you make to your method)?\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f1f0d-6864-419c-b980-dc4b7ee92d76",
   "metadata": {},
   "source": [
    "All three policies take 79 steps to solve each of the three problems (P1_B0/P1_G0, P1_B1/P1_G0, P2_B1/P2_G0), for a total of 237 steps each. This suggests that in these particular scenarios, the different strategies converge to similar behavior after initial observations—the robot quickly gains enough information that safe, reckless, and belief-space planning all identify the same optimal paths.\n",
    "\n",
    "If planning is very expensive compared to execution, choose the reckless planner since it only plans once initially and replans only when absolutely necessary. If execution is very expensive compared to planning, then choose the safe-and-smart planner since it guarantees no wasted moves into unsafe territory, though could modify it to replan more proactively when significant new information is discovered rather than executing a stale plan."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
