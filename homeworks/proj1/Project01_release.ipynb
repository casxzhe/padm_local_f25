{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0028472",
   "metadata": {},
   "source": [
    "**This project is due Wednesday, October 22, 2025 at 11:59 pm. Please plan ahead and submit your work on time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a355c1",
   "metadata": {
    "id": "97a355c1"
   },
   "source": [
    "<center><h1>Grad Project #1</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2946f4ee-7fdf-47c6-991d-079b0c2df9fc",
   "metadata": {},
   "source": [
    "In this first project for 16.413 / 6.4132, we are going to look at the search and rescue domain using symbolic representations. We are going to look at both planning using PDDL, and also inference using PDDL. This project isn't going to focus on implementing specific algorithms however -- we're going to use two libraries: `pyperplan` and `sympy`. (You'll remember them from problem sets 3 and 4). \n",
    "\n",
    "The project is structured as follows: \n",
    "\n",
    "0. [Credit for Contributors (required)](#contributors)\n",
    "1. [Planning in Search and Rescue (15 points)](#planning_in_sar)\n",
    "    1. [Search and Rescue Warmup 1 (5 points)](#warmup_1)\n",
    "    2. [Search and Rescue Warmup 2 (5 points)](#warmup_2)\n",
    "    3. [Search and Rescue PDDL Planner (5 points)](#sar_pddl)\n",
    "2. [Inference from Observations (20 points)](#inference)\n",
    "    1. [Inferring unknown values (10 points)](#infer_unknowns)\n",
    "    2. [Belief update (10 points)](#belief_update)\n",
    "3. [Putting It Together (35 points)](#integrated)\n",
    "    1. [Safe but not so smart (7 points)](#safe_no_smart)\n",
    "    2. [Safe and smart (7 points)](#safe_smart)\n",
    "    3. [Reckless (7 points)](#reckless)\n",
    "    4. [Safe and smart if possible, else reckless (7 points)](#safe_smart_reckless)\n",
    "    5. [Looks before it leaps (7 points)](#look_before)\n",
    "4. [Analysis (30 points)](#analysis)\n",
    "5. [Feedback](#feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b6fc67-c474-4e25-9382-a8769d43877e",
   "metadata": {},
   "source": [
    "## <a id=\"contributors\"></a>0. Credit for Contributors\n",
    "\n",
    "List the various students, lecture notes, or online resouces that helped you complete this project:\n",
    "\n",
    "Ex: I worked with Bob on the inference.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4fa58b",
   "metadata": {},
   "source": [
    "--> *(double click on this cell to delete this text and type your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254f9679",
   "metadata": {
    "id": "254f9679"
   },
   "source": [
    "## Imports and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160041fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sympy import Symbol, And, Or, satisfiable\n",
    "from utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from principles_of_autonomy.grader import Grader\n",
    "from principles_of_autonomy.notebook_tests.proj_1 import TestProj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe23496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_policy(belief_map, true_map, problem, policy):\n",
    "    \"\"\"Test a policy on a SearchAndRescue problem.\n",
    "\n",
    "    Args:\n",
    "        belief_map: A numpy array specifying the belief map\n",
    "        true_map:   A numpy array specifying the state map\n",
    "        problem:    A SearchAndRescueProblem instance\n",
    "        policy:     A policy returned by a policy making fn.\n",
    "                    e.g. make_planner_policy(problem, planner)\n",
    "    \"\"\"\n",
    "    height, width = true_map.shape\n",
    "    bottom, right = height - 1, width - 1\n",
    "    robot = (0, right)\n",
    "    hospital = (bottom, right)\n",
    "    people = {'pp': (bottom, right - 1)}  # Peter Parker\n",
    "    carrying = None\n",
    "    # Environment state\n",
    "    env_state = State(robot=robot,\n",
    "                      hospital=hospital,\n",
    "                      people=people,\n",
    "                      carrying=carrying,\n",
    "                      state_map=true_map)\n",
    "    # Initial belief: omniscient\n",
    "    b0 = BeliefState(robot=robot,\n",
    "                     hospital=hospital,\n",
    "                     people=people,\n",
    "                     carrying=carrying,\n",
    "                     state_map=belief_map)\n",
    "    # Do it\n",
    "    return agent_loop(problem, env_state, policy, b0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3437bb42-2f9f-4904-a2d3-02f64a4bd374",
   "metadata": {},
   "source": [
    "## <a id=\"planning_in_sar\"></a> 1. Planning in Search and Rescue (15 points)\n",
    "\n",
    "Let's say that we have a \"search and rescue\" robot who is charged with navigating a sometimes dangerous grid to find and help people in need. We will restrict ourselves to a deterministic problem domain; we will however look at both fully observed and partially observed cases.\n",
    "\n",
    "Let us first focus on a single planning problem in the search-and-rescue domain, illustrated below:\n",
    "\n",
    "![search and rescue problem](sar_problem.png)\n",
    "\n",
    "This problem features four \"people\" (bears) with names p1, p2, p3, and p4. A robot, initialized in the top left corner, should navigate to each person, pick them up one by one, and deliver them to the hospital (bottom right).\n",
    "\n",
    "* We always know the locations of the people, the robot, and the hospital. \n",
    "* Some locations may have walls in them.  **You know about all the walls in advance, as well.**\n",
    "* There is also fire!  And smoke!  But, initially, you may not know which locations have fire and/or smoke. Therefore, you need to move around in the domain, make observations, update your belief (e.g., infer whether there may be fire or smoke in the cells you haven't observed yet), make plans, and rescue bears.\n",
    "* Whenever the robot enters a grid cell, it observes the true environment state of all the neighboring cells.  Each environment cell contains exactly one of:  wall ('W'), fire ('F'), smoke ('S') or nothing (clear, 'C').\n",
    "* The robot may safely enter any cell that is clear ('C') or contains smoke ('S').\n",
    "\n",
    "We will first consider planning to navigate to, pick up, and drop off people at a hospital, and we are going to ask you to put this all together into a planning and execution system!\n",
    "\n",
    "Take a look at the code.  `State` is a class with the following attributes:\n",
    "\n",
    "* \"state_map\": a 2D numpy array of characters 'W', 'F', 'S', 'C'.\n",
    "* \"robot\": A (row, col) representing the robot's loc.\n",
    "* \"hospital\": A (row, col) representing the hospital's loc.\n",
    "* \"carrying\": The str name of a person being carried, or None, if no person is being carried.\n",
    "* \"people\": A dict mapping str people names to (row, col) locs. If a person is being carried, they do not appear in this dict.\n",
    "\n",
    "States have a couple of useful methods: `render` returns a string representation of the state (which can be printed) and `copy` does what you would expect. `get_safe_grid` returns a boolean numpy array where True represents a safe space (not fire or wall).\n",
    "\n",
    "Actions are strings:\n",
    "* \"up\" / \"down\" / \"left\" / \"right\" : Moves the robot. The robot cannot move into obstacles or off the map.\n",
    "* \"pickup-{person}\": If the robot is at the person, and if the robot is not already carrying someone, pick up this person.\n",
    "* \"dropoff\": If the robot is carrying a person, they are dropped off at the robot's current location.  *Allow for there being multiple dropoff locations, even though we will only dropoff at hospitals in this example.*\n",
    "\n",
    "Please now take a moment to read the docstring for `SearchAndRescueProblem` to make sure that you understand the state and action spaces.\n",
    "\n",
    "Finally, we're going to use a Python PDDL planner called `pyperplan` [(more info here)](https://github.com/aibasel/pyperplan) to find our plans. \n",
    "\n",
    "Let's familiarize ourselve with State and SearchAndRescueProblem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef53809",
   "metadata": {
    "id": "8ef53809"
   },
   "source": [
    "### <a id=\"warmup_1\"></a> 1A. Search and Rescue Warmup 1 (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22714ba3-f8cd-4a02-9923-29f08db6af49",
   "metadata": {},
   "source": [
    "Let's make sure we can access fields of the SearchAndRescue State. Please write a function to check if a row and column have an obstacle in a SearchAndRescue State.\n",
    "\n",
    "For reference, our solution is **1** line(s) of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045a6db7-d3bb-458b-9dd7-4070fce30f30",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def sar_warmup1(sar_state: State, row: int, col: int) -> bool:\n",
    "    \"\"\"Check if a row and col have an obstacle in a SearchAndRescueProblem\n",
    "    state.\n",
    "\n",
    "    Args:\n",
    "      sar_state: A SearchAndRescue State.\n",
    "      row: An int.\n",
    "      col: An int.\n",
    "\n",
    "    Returns:\n",
    "      has_obstacle: True if (row, col) has an obstacle(wall) in sar_state.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a5283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1\n",
    "Grader.run_single_test_inline(TestProj1, \"test_01_warmup_1\", locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65deb8e-13d8-434e-a8e3-9d25b12137ac",
   "metadata": {
    "id": "8ef53809"
   },
   "source": [
    "### <a id=\"warmup_2\"></a> 1B. Search and Rescue Warmup 2 (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1f6d6b",
   "metadata": {
    "id": "9f1f6d6b"
   },
   "source": [
    "Let's make sure we know how to encode a plan. Please write a function that returns a hard-coded list of actions that will deliver person 'p1' (in the image above) to the hospital location. (You'll need to work out the plan for yourself -- don't use `pyperplan` yet!)\n",
    "\n",
    "For reference, our solution is **1** line(s) of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5634908",
   "metadata": {
    "id": "c5634908",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def sar_warmup2() -> list[str]:\n",
    "    \"\"\"Hand-code a list of actions that will deliver person 'p1' to the\n",
    "    hospital location.\n",
    "\n",
    "    Returns:\n",
    "      actions: A list of str actions that will take person p1 to the hospital loccation.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb6e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2\n",
    "Grader.run_single_test_inline(TestProj1, \"test_02_warmup_2\", locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9925e4",
   "metadata": {
    "id": "1e9925e4"
   },
   "source": [
    "### <a id=\"sar_pddl\"></a> 1C. Search and Rescue PDDL Planner (5 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e4738",
   "metadata": {
    "id": "2f9e4738"
   },
   "source": [
    "Now that you're warmed up, let's try making a planner to solve a SearchAndRescueProblem!\n",
    "\n",
    "The core function in this planner class is 'get_plan'. This function needs to do the following:\n",
    "1. Create PDDL domain and problem strings for search and rescue. The operators should work for any grid size, obstacles, people locations, and hospital location.\n",
    "2. Invoke `run_planning` using the given `search_algo` search algorithm with the `heuristic` heuristic.\n",
    "3. Convert the output of `run_planning` (pyperplan Operators) into actions that can be executed, via `execute_plan`.\n",
    "\n",
    "We have given you most of the structure of the needed functions, but you will need to look (carefully!) through the provided python to find the `TODO` sections that you need to complete. \n",
    "\n",
    "For reference, 'get_plan' takes ~1-2 seconds to run with our implementation if using 'gbf' search and 'hff' heuristic. To get credit on Gradescope, make sure that your function finishes in <10 seconds.\n",
    "\n",
    "**Notes**:\n",
    "* In this problem, you will need to construct somewhat complicated strings.  We *strongly* encourage you to read about [Python-3 f-strings](https://www.digitalocean.com/community/tutorials/how-to-use-f-strings-to-create-strings-in-python-3) which make this process much easier than the alternatives.\n",
    "* You may find `state.render()` useful for debugging.\n",
    "* We also highly recommend printing out the domain and problem after they have been created, and copying them into [editor.planning.domains](http://editor.planning.domains) to check whether it's possible to find a plan. This editor can be helpful for syntax checking.\n",
    "* We also recommend writing careful test cases for yourself --- it's really easy to forget preconditions or effects. When we were debugging this, we forgot to make sure that the robot was at the location of the person that it picked up, so the plans were (confusingly) super short! \n",
    "* The image above with the robot and the bears is a faithful depiction of the initial state. For example, the initial locations of the people are: `\"p1\": (4, 0), \"p2\": (6, 0), \"p3\": (0, 6), \"p4\": (3, 3)`.\n",
    "* One part of this problem that may be initially counterintuitive is the way that we'll represent locations in PDDL. In the problem, a location is a tuple of integers. PDDL does not support such representations -- everything needs to be just an object with a string name.\n",
    "So to represent a location like (3, 5), we will make a string `\"l3-5\"` (where the first character there is a lowercase L), and we'll create an object with that name, of type \"location\". We will also need a way to encode the fact that the robot can only move between adjacent locations in the grid.\n",
    "In Python, we can compare the numeric values of locations like (3, 5) and (3, 6) to see if they are neighbors. But in PDDL, all we have are the objects with string names, and we need to encode everything in terms of predicates. So, we will create a predicate `(conn ?v0 - location ?v1 - location ?v2 - direction)`, which says that location `?v0` is connected to location `?v1` in direction `?v2`. For example, `(conn l3-5 l3-6 right)` might appear in the initial state. We can then use these `conn` predicates in the preconditions of a `move` operator to encode the fact that the robot can only move between adjacent locations.\n",
    "* We do not recommend modelling the hospital explicitly with special objects / types / predicates. Instead, the goal should be to deliver all people to the hospital, that is, `l6-6`.\n",
    "In words, the goal should be `\"person1 is at l6-6 and person2 is at l6-6 and person3 is at l6-6 and person4 is at l6-6\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d72e0d",
   "metadata": {
    "id": "c1d72e0d"
   },
   "outputs": [],
   "source": [
    "class SearchAndRescuePlanner:\n",
    "    \"\"\"A planner for a search and rescue problem.\n",
    "\n",
    "    The core function in this class is 'get_plan'\n",
    "    This function does the following:\n",
    "        1. Create PDDL domain and problem strings for search and rescue. The operators should work for any grid size, obstacles, people locations, and hospital location.\n",
    "        2. Invoke `run_planning` using the given `search_algo` search algorithm with the `heuristic` heuristic.\n",
    "        3. Convert the output of run_planning (pyperplan Operators) into actions\n",
    "           that can be given to the SearchAndRescueProblem.\n",
    "\n",
    "    Example Usage:\n",
    "        problem = SearchAndRescueProblem()\n",
    "        state = State()\n",
    "\n",
    "        planner = SearchAndRescuePlanner(search_algo='astar', heuristic='lmcut')\n",
    "        plan, plan_time = planner.get_plan(state)\n",
    "        state = execute_plan(problem, plan, state)\n",
    "\n",
    "    'get_plan' Returns:\n",
    "        plan: A list of actions; each action is a str, see SearchAndRescueProblem.\n",
    "        plan_time: Total planning time(sec) used for plan searching.\n",
    "\n",
    "    For reference, 'get_plan' takes ~1-2 seconds to run with our implementation if using 'gbf' search and 'lmcut' heuristic.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, search_algo='astar', heuristic='lmcut'):\n",
    "        self.search_algo = search_algo\n",
    "        self.heuristic = heuristic\n",
    "\n",
    "    def generate_domain_pddl(self,\n",
    "                             domain_name,\n",
    "                             added_operators='',\n",
    "                             added_predicates=''):\n",
    "        # <<< TODO: fill in missing parts in the PDDL domain below >>>\n",
    "        predicates_str = \"\"\"(conn ?v0 - location ?v1 - location ?v2 - direction)\n",
    "        (is-clear ?v0 - location)\n",
    "        ; TODO: write more here\n",
    "        ; \n",
    "        \"\"\"\n",
    "        \n",
    "        # <<< TODO: fill in missing parts in the PDDL domain below >>>\n",
    "        operators_str = \"\"\"(:action move-robot\n",
    "    :parameters (?from - location ?to - location ?dir - direction)\n",
    "    :precondition (and\n",
    "      (conn ?from ?to ?dir)\n",
    "      ; TODO: write more here\n",
    "      ; \n",
    "    )\n",
    "    :effect (and\n",
    "      ; TODO: write more here\n",
    "      ; \n",
    "    )\n",
    "  )\n",
    "  (:action pickup-person\n",
    "    :parameters (?person - person ?loc - location)\n",
    "    :precondition (and\n",
    "      ; TODO: write more here\n",
    "      ; \n",
    "    )\n",
    "    :effect (and\n",
    "      ; TODO: write more here\n",
    "      ; \n",
    "    )\n",
    "  )\n",
    "  (:action dropoff-person\n",
    "    :parameters (?person - person ?loc - location)\n",
    "    :precondition (and\n",
    "      ; TODO: write more here\n",
    "      ; \n",
    "    )\n",
    "    :effect (and\n",
    "      ; TODO: write more here\n",
    "      ; \n",
    "    )\n",
    "  )\"\"\"\n",
    "\n",
    "        domain_pddl = f\"\"\"(define (domain {domain_name})\n",
    "    (:requirements :typing)\n",
    "    (:types person location direction)\n",
    "    (:constants\n",
    "      down - direction\n",
    "      left - direction\n",
    "      right - direction\n",
    "      up - direction\n",
    "    )\n",
    "    (:predicates\n",
    "      {predicates_str}\n",
    "      {added_predicates}\n",
    "    )\n",
    "    {operators_str}\n",
    "    {added_operators}\n",
    ")\"\"\"\n",
    "        return domain_pddl\n",
    "\n",
    "    def get_plan(self, state):\n",
    "        search_algo, heuristic = self.search_algo, self.heuristic\n",
    "        domain_name, added_predicate, added_operator = self.update_pddl_domain()\n",
    "        domain_pddl = self.generate_domain_pddl(\n",
    "            domain_name,\n",
    "            added_operators=added_operator,\n",
    "            added_predicates=added_predicate)\n",
    "        # Create objects str\n",
    "        obj_str = self.get_obj_strs(state)\n",
    "\n",
    "        # Create init str\n",
    "        init_str = self.get_init_strs(state)\n",
    "\n",
    "        # Create goal str\n",
    "        goal_str = self.get_goal_strs(state)\n",
    "\n",
    "        problem_pddl = f\"\"\"(define (problem searchandrescue) (:domain {domain_name})\n",
    "      (:objects\n",
    "      {obj_str}\n",
    "      )\n",
    "      (:init\n",
    "      {init_str}\n",
    "      )\n",
    "      (:goal (and {goal_str}))\n",
    "    )\"\"\"\n",
    "\n",
    "        start_time = time.time()\n",
    "        plan = run_planning(domain_pddl, problem_pddl, search_algo, heuristic)\n",
    "        time_elapsed = time.time() - start_time\n",
    "        if plan is None:\n",
    "            print(\"Failed to find a plan.\")\n",
    "            return None, time_elapsed\n",
    "\n",
    "        # Convert operators to actions\n",
    "        actions = self.parse_plan(plan)\n",
    "        return actions, time_elapsed\n",
    "\n",
    "    def get_obj_strs(self, state):\n",
    "        height, width = state.state_map.shape\n",
    "        objects_strs = [f\"{person} - person\" for person in state.people]\n",
    "        # <<< TODO: add object strs for locations >>>\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "        if state.carrying is not None:\n",
    "            objects_strs.append(f\"{state.carrying} - person\")\n",
    "        objects_str = \" \".join(objects_strs)\n",
    "        return objects_str\n",
    "\n",
    "    def get_init_strs(self, state):\n",
    "        height, width = state.state_map.shape\n",
    "        robot_r, robot_c = state.robot\n",
    "        init_strs = [f\"(robot-at l{robot_r}-{robot_c})\"]\n",
    "        for person, (r, c) in state.people.items():\n",
    "            init_strs.append(f\"(person-at {person} l{r}-{c})\")\n",
    "        if state.carrying is not None:\n",
    "            init_strs.append(f\"(carrying {state.carrying})\")\n",
    "        else:\n",
    "            init_strs.append(\"(handsfree)\")\n",
    "            \n",
    "        deltas = {\n",
    "            \"up\": (-1, 0),\n",
    "            \"down\": (1, 0),\n",
    "            \"left\": (0, -1),\n",
    "            \"right\": (0, 1),\n",
    "        }\n",
    "        \n",
    "        safe_grid = state.get_safe_grid()\n",
    "        for r in range(height):\n",
    "            for c in range(width):\n",
    "                # Here we're going to add one (conn ...) atom for every pair\n",
    "                # of adjacent locations.\n",
    "                for direction, (dr, dc) in deltas.items():\n",
    "                    if not (0 <= r + dr < height and 0 <= c + dc < width):\n",
    "                        continue\n",
    "                    # For example, if r == 0, c == 0, dr == 0, dc == 1, then\n",
    "                    # this line adds the atom (conn l0-0 l0-1 right).\n",
    "                    init_strs.append(\n",
    "                        f\"(conn l{r}-{c} l{r + dr}-{c + dc} {direction})\")\n",
    "                # <<< TODO: add more init strs >>>\n",
    "                raise NotImplementedError()\n",
    "\n",
    "        init_str = \" \".join(init_strs)\n",
    "        return init_str\n",
    "\n",
    "    def get_goal_strs(self, state):\n",
    "        goal_strs = []\n",
    "        hospital_r, hospital_c = state.hospital\n",
    "        # <<< TODO: add goal strs >>>\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "\n",
    "        if state.carrying is not None:\n",
    "            # <<< TODO: add goal strs >>>\n",
    "            raise NotImplementedError()\n",
    "            pass\n",
    "        goal_str = \" \".join(goal_strs)\n",
    "        return goal_str\n",
    "\n",
    "    def update_pddl_domain(self):\n",
    "        domain_name = 'searchandrescue'\n",
    "        added_predicate = ''\n",
    "        added_operator = ''\n",
    "        return domain_name, added_predicate, added_operator\n",
    "\n",
    "    def parse_plan(self, plan):\n",
    "        actions = []\n",
    "        for op in plan:\n",
    "            if \"move-robot\" in op.name:\n",
    "                _, direction = op.name[:-1].rsplit(\" \", 1)\n",
    "                action = direction\n",
    "            elif \"pickup-person\" in op.name:\n",
    "                _, person, _ = op.name.split(\" \")\n",
    "                action = f\"pickup-{person}\"\n",
    "            else:\n",
    "                assert \"dropoff-person\" in op.name\n",
    "                action = \"dropoff\"\n",
    "            actions.append(action)\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13e38b9",
   "metadata": {
    "id": "f13e38b9"
   },
   "source": [
    "Visualize to make sure your planner does what you expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bb3232",
   "metadata": {
    "id": "29bb3232",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sar_pddl_problem = SearchAndRescueProblem()\n",
    "sar_pddl_planner = SearchAndRescuePlanner(search_algo=\"gbf\", heuristic=\"hff\")\n",
    "sar_pddl_state = State()\n",
    "sar_pddl_plan, plan_time = sar_pddl_planner.get_plan(sar_pddl_state)\n",
    "result = execute_plan(problem=sar_pddl_problem, state=sar_pddl_state, plan=sar_pddl_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3\n",
    "Grader.run_single_test_inline(TestProj1, \"test_03_sar_pddl\", locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3b537",
   "metadata": {
    "id": "d8f3b537"
   },
   "source": [
    "## <a id=\"inference\"></a> 2. Inference from Observations (20 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3ae309-085d-489f-892d-1c1ee99c5d18",
   "metadata": {},
   "source": [
    "The real world is **partially observable**, where the robot can only see part of the world at a time. To handle this, we introduce the idea of a **belief**. A belief is simply the robot’s current knowledge about the world. It may include some unknowns, and as the robot moves and makes observations, the belief gets updated. In this project, a belief will look like the grid maps you’ve seen already, except with `\"U\"` entries for unknown cells. As the robot observes cells, `\"U\"` entries will be replaced with `\"C\"`, `\"F\"`, `\"S\"`, or `\"W\"`. We will also use logical rules (inference) to fill in what must be true.\n",
    "\n",
    "Now, let's look at the inference problem.  This is similar to the problem we saw in PSet 3. We will consider several problems with varying grid sizes and different sets of observations. For example, consider the grid below:\n",
    "```\n",
    "# Fire, Unknown, Clear, Smoke, Wall\n",
    "GRID0 = np.array([\n",
    "  [\"F\", \"U\", \"C\"],\n",
    "  [\"W\", \"C\", \"U\"],\n",
    "  [\"U\", \"U\", \"C\"]\n",
    "], dtype=object)\n",
    "```\n",
    "This grid has 9 locations and 5 observations: there is fire in the top left, wall below it, and the center, top right, and bottom right locations are all known to be clear of smoke or fire.\n",
    "\n",
    "We will assume the following axioms:\n",
    "1. Each location has exactly one of {smoke, fire, clear, wall}.\n",
    "\n",
    "2. There is smoke at a location only if there is a fire in at least one of the adjacent (above, below, left, right) locations. Diagonals are not adjacent!\n",
    "\n",
    "3. There is smoke _or_ fire at a location if there is a fire in at least one of the adjacent locations, unless it's known to be 'W'.\n",
    "\n",
    "Take a moment to run your human inference engine: which unknown values in the grid above can be determined?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea3d8da",
   "metadata": {
    "id": "1ea3d8da"
   },
   "source": [
    "### <a id=\"infer_unknowns\"></a> 2A. Inferring unknown values (10 points)\n",
    "\n",
    "Please write a program that takes a grid as input and infers unknown values.\n",
    "\n",
    "Your program should output a new grid with all determinable unknown values replaced with the inferred value. If an unknown value cannot be determined, it should be left unknown.\n",
    "\n",
    "**Your program should use sympy.**\n",
    "\n",
    "For reference, our solution is **63** line(s) of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932cbf09",
   "metadata": {
    "id": "932cbf09",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def infer_unknown_values(grid):\n",
    "    \"\"\"Fill in any unknown values in the grid that can be inferred.\n",
    "\n",
    "    Args: grid: A list of lists of \"F\", \"U\", \"S\", \"W\", or \"C\".\n",
    "    Returns:\n",
    "      inferred_grid: A copy of grid with some unknown values replaced.\n",
    "\n",
    "    Example:\n",
    "      >> grid = [\n",
    "      >>   [\"F\", \"U\", \"C\"],\n",
    "      >>   [\"W\", \"C\", \"U\"],\n",
    "      >>   [\"U\", \"U\", \"C\"]\n",
    "      >> ]\n",
    "      >> infer_unknown_values(grid)\n",
    "      >> [[\"F\" \"S\" \"C\"]\n",
    "      >>  [\"W\" \"C\" \"C\"]\n",
    "      >>  [\"U\" \"U\" \"C\"]]\n",
    "    \"\"\"\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e7c2e",
   "metadata": {
    "id": "471e7c2e",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Note: we're providing these unit tests to help you. \n",
    "# The grading tests are not just these tests.\n",
    "\n",
    "assert infer_unknown_values([[\"U\", \"F\"]]) == [[\"U\", \"F\"]]\n",
    "assert infer_unknown_values([[\"F\", \"U\", \"C\"], [\"S\", \"C\", \"U\"], [\"U\", \"U\", \"C\"]]) == [[\"F\", \"S\", \"C\"], [\"S\", \"C\", \"C\"], [\"U\", \"U\", \"C\"]]\n",
    "assert infer_unknown_values([[\"U\", \"C\", \"C\"], [\"S\", \"C\", \"U\"], [\"U\", \"U\", \"C\"]]) == [[\"C\", \"C\", \"C\"], [\"S\", \"C\", \"C\"], [\"F\", \"S\", \"C\"]]\n",
    "assert infer_unknown_values([[\"U\", \"S\", \"C\", \"U\"], [\"U\", \"U\", \"C\", \"U\"], [\"U\", \"S\", \"C\", \"U\"]]) == [[\"F\", \"S\", \"C\", \"C\"], [\"U\", \"U\", \"C\", \"C\"], [\"F\", \"S\", \"C\", \"C\"]]\n",
    "assert infer_unknown_values([[\"U\", \"U\", \"C\", \"U\", \"U\", \"U\", \"U\", \"U\"], [\"C\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"C\", \"C\"], [\"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"C\", \"C\"], [\"U\", \"C\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"F\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\"]]) == [[\"C\", \"C\", \"C\", \"U\", \"U\", \"U\", \"U\", \"U\"], [\"C\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"C\", \"C\"], [\"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"C\", \"C\"], [\"U\", \"C\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"F\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\"]]\n",
    "assert infer_unknown_values([[\"C\", \"U\", \"C\", \"U\", \"U\", \"C\", \"U\"], [\"U\", \"W\", \"W\", \"U\", \"C\", \"W\", \"W\"], [\"U\", \"F\", \"U\", \"U\", \"U\", \"F\", \"U\"], [\"C\", \"S\", \"W\", \"C\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"W\", \"U\", \"W\", \"U\", \"U\"], [\"C\", \"C\", \"U\", \"C\", \"U\", \"W\", \"U\"], [\"U\", \"W\", \"C\", \"U\", \"W\", \"U\", \"C\"]]) == [[\"C\", \"C\", \"C\", \"C\", \"C\", \"C\", \"C\"], [\"C\", \"W\", \"W\", \"C\", \"C\", \"W\", \"W\"], [\"S\", \"F\", \"U\", \"U\", \"S\", \"F\", \"U\"], [\"C\", \"S\", \"W\", \"C\", \"U\", \"U\", \"U\"], [\"C\", \"C\", \"W\", \"C\", \"W\", \"U\", \"U\"], [\"C\", \"C\", \"C\", \"C\", \"C\", \"W\", \"U\"], [\"C\", \"W\", \"C\", \"C\", \"W\", \"C\", \"C\"]]\n",
    "assert infer_unknown_values([[\"C\", \"U\", \"C\", \"U\", \"U\", \"C\", \"U\"], [\"U\", \"W\", \"W\", \"U\", \"C\", \"W\", \"W\"], [\"U\", \"F\", \"U\", \"U\", \"U\", \"F\", \"U\"], [\"C\", \"S\", \"W\", \"C\", \"U\", \"F\", \"U\"], [\"U\", \"U\", \"W\", \"U\", \"W\", \"U\", \"U\"], [\"C\", \"C\", \"U\", \"C\", \"U\", \"W\", \"F\"], [\"U\", \"W\", \"C\", \"U\", \"W\", \"U\", \"U\"]]) == [[\"C\", \"C\", \"C\", \"C\", \"C\", \"C\", \"C\"], [\"C\", \"W\", \"W\", \"C\", \"C\", \"W\", \"W\"], [\"S\", \"F\", \"U\", \"U\", \"S\", \"F\", \"U\"], [\"C\", \"S\", \"W\", \"C\", \"S\", \"F\", \"U\"], [\"C\", \"C\", \"W\", \"C\", \"W\", \"U\", \"U\"], [\"C\", \"C\", \"C\", \"C\", \"C\", \"W\", \"F\"], [\"C\", \"W\", \"C\", \"C\", \"W\", \"U\", \"U\"]]\n",
    "print('Tests passed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a0141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4\n",
    "Grader.run_single_test_inline(TestProj1, \"test_04_infer_unknown\", locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46909c4",
   "metadata": {
    "id": "b46909c4"
   },
   "source": [
    "### <a id=\"belief_update\"></a> 2B. Belief update (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10831e4",
   "metadata": {
    "id": "c10831e4"
   },
   "source": [
    "When the robot acts in the environment, its knowledge must change in three ways:\n",
    "1. **Transition step** – move the robot’s position forward based on the chosen action\n",
    "   (e.g., if the action is `down`, the robot moves one square down).\n",
    "2. **Observation step** – incorporate any new sensor information about nearby cells.\n",
    "3. **Inference step** – apply logical rules to replace `\"U\"` with `\"C\"`, `\"F\"`, or `\"S\"`\n",
    "   wherever those values can be deduced.\n",
    "\n",
    "This process is called a **belief update**. It is nothing more than keep track of what the robot now knows after acting and looking around.\n",
    "\n",
    "Now let us use our ability to infer unknown values to finish the implementation of the update method for BeliefState.\n",
    "\n",
    "Make sure to look at the utilities defined at the top of this notebook, although you may not need to use all of them.\n",
    "\n",
    "For reference, our solution is **12** line(s) of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c807b37",
   "metadata": {
    "id": "1c807b37",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class BeliefState(State):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if \"state_map\" not in kwargs:\n",
    "            self.state_map = np.array([['U', 'U', 'U', 'U', 'U', 'U', 'U'],\n",
    "                                       ['U', 'W', 'W', 'U', 'U', 'W', 'W'],\n",
    "                                       ['U', 'U', 'U', 'U', 'U', 'U', 'U'],\n",
    "                                       ['U', 'U', 'W', 'U', 'U', 'U', 'U'],\n",
    "                                       ['U', 'U', 'W', 'U', 'W', 'U', 'U'],\n",
    "                                       ['U', 'U', 'U', 'U', 'U', 'W', 'U'],\n",
    "                                       ['U', 'W', 'U', 'U', 'W', 'U', 'U']],\n",
    "                                      dtype=str)\n",
    "\n",
    "    def update(self, problem, obs, action=None):\n",
    "        \"\"\"\n",
    "        problem: SearchAndRescueProblem instance\n",
    "        obs: {loc: entry, loc: entry,...}\n",
    "        act: string or None\n",
    "\n",
    "        # <<< TODO: >>>\n",
    "            1. Do transition from action (if any)\n",
    "            2. Update from observation\n",
    "            3. Do inference\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_optimistic_state(self):\n",
    "        \"\"\"Returns a copy of the belief with a completed map in which Unknowns\n",
    "        are assumed to be Clear.\"\"\"\n",
    "        new_state = self.copy()\n",
    "        new_state.state_map[self.state_map == 'U'] = 'C'\n",
    "        return new_state\n",
    "\n",
    "    def get_careful_state(self):\n",
    "        \"\"\"Returns a copy of the belief.\n",
    "\n",
    "        Unknown states will not be treated as safe, see get_safe_grid.\n",
    "        \"\"\"\n",
    "        return self.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafd16ea",
   "metadata": {
    "id": "cafd16ea"
   },
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb50542c",
   "metadata": {
    "id": "fb50542c",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def beliefupdate_test1():\n",
    "    state_map = np.array([[\"C\", \"S\", \"C\", \"C\", \"C\"], [\"S\", \"F\", \"S\", \"C\", \"C\"],\n",
    "                          [\"S\", \"F\", \"S\", \"S\", \"S\"], [\"S\", \"F\", \"F\", \"F\", \"F\"],\n",
    "                          [\"C\", \"S\", \"S\", \"S\", \"S\"], [\"C\", \"C\", \"C\", \"C\", \"C\"]])\n",
    "    beliefstate_map = np.array([[\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"U\", \"U\", \"U\", \"U\", \"U\"]])\n",
    "    problem = SearchAndRescueProblem()\n",
    "    state = State(state_map=state_map)\n",
    "    bel = BeliefState(state_map=beliefstate_map)\n",
    "    observation = problem.get_observation(state)\n",
    "    new_bel = bel.update(problem, observation)\n",
    "    assert new_bel.robot == (0, 0)\n",
    "    assert new_bel.state_map.tolist() == [['C', 'S', 'U', 'U', 'U'],\n",
    "                                          ['S', 'U', 'U', 'U', 'U'],\n",
    "                                          ['U', 'U', 'U', 'U', 'U'],\n",
    "                                          ['U', 'U', 'U', 'U', 'U'],\n",
    "                                          ['U', 'U', 'U', 'U', 'U'],\n",
    "                                          ['U', 'U', 'U', 'U', 'U']]\n",
    "beliefupdate_test1()\n",
    "\n",
    "\n",
    "def beliefupdate_test2():\n",
    "    state_map = np.array([[\"C\", \"S\", \"C\", \"C\", \"C\"], [\"S\", \"F\", \"S\", \"C\", \"C\"],\n",
    "                          [\"S\", \"F\", \"S\", \"S\", \"S\"], [\"S\", \"F\", \"F\", \"F\", \"F\"],\n",
    "                          [\"C\", \"S\", \"S\", \"S\", \"S\"], [\"C\", \"C\", \"C\", \"C\", \"C\"]])\n",
    "    beliefstate_map = np.array([[\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"S\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"U\", \"U\", \"U\", \"U\", \"U\"]])\n",
    "    problem = SearchAndRescueProblem()\n",
    "    state = State(state_map=state_map)\n",
    "    bel = BeliefState(state_map=beliefstate_map)\n",
    "\n",
    "    new_state, _ = problem.get_next_state(state, 'down')\n",
    "    observation = problem.get_observation(new_state)\n",
    "    new_bel = bel.update(problem, observation, 'down')\n",
    "    assert new_bel.robot == (1, 0)\n",
    "    assert new_bel.state_map.tolist() == [['C', 'S', 'U', 'U', 'U'],\n",
    "                                          ['S', 'F', 'U', 'U', 'U'],\n",
    "                                          ['S', 'U', 'U', 'U', 'U'],\n",
    "                                          ['U', 'U', 'U', 'U', 'U'],\n",
    "                                          ['U', 'U', 'U', 'U', 'U'],\n",
    "                                          ['U', 'U', 'U', 'U', 'U']]\n",
    "beliefupdate_test2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a64f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 5\n",
    "Grader.run_single_test_inline(TestProj1, \"test_05_belief_update\", locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3795be7-3c70-4925-a96d-92b6d89c6d02",
   "metadata": {},
   "source": [
    "## <a id=\"integrated\"></a> 3. Putting It Together (35 points)\n",
    "\n",
    "It's time to bring the planning and the inference together! Look at the procedure `agent_loop` that takes as input:\n",
    "\n",
    "* \"initial_state\": (a true state of the environment, which includes a state map, as well as the current locations of the hospital, the robot and the people and whether the robot is carrying someone.\n",
    "* \"initial_belief\" (an initial belief state, which is like an environment state, except that the state map may include characters 'U' indicating that the contents of a location is unknown)\n",
    "* \"policy\" : a procedure that takes in a belief state and returns the next action to take;  the action can be one of the original actions or '*Success*' (which means the goal has been achieved and all the people are at the hospital) or '*Failure*' (which means that the agent is certain that the goal is impossible to achieve.)  \n",
    "* \"max_steps\" : just a total number of steps to run the simulation to avoid infinite loops\n",
    "\n",
    "We are going to ask you to write five different policies for this domain.\n",
    "\n",
    "1. Safe but not so smart\n",
    "1. Safe and smart\n",
    "1. Reckless\n",
    "1. Safe and smart if possible, else reckless\n",
    "1. Looks before it leaps\n",
    "\n",
    "### <a id=\"safe_no_smart\"></a> 3A. Safe but not so smart (7 points)\n",
    "\n",
    "The agent is scared and just running directly to the hospital. However, it at least takes observations into account as it moves.\n",
    "\n",
    "Let's make an agent that:\n",
    "\n",
    "* Updates the belief state based on every observation using propositional inference (implement the `belief.update` method that gets called in `agent_loop`).\n",
    "\n",
    "* Executes a policy that, given the currently updated belief, checks to see whether it can move safely into a square that is closer (in Manhattan distance) to the hospital.  If so, it returns the action that would move it closer.  If it reaches the hospital, it returns `*Success*`.  If it cannot safely make a move (due to walls or fire) closer to the hospital, it waves its arms in anguish and returns `*Failure*`.\n",
    "\n",
    "For reference, our solution is **18** line(s) of code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e721a1",
   "metadata": {
    "id": "d9e721a1",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_greedy_policy(problem):\n",
    "    def policy(belief):\n",
    "        \"\"\"Returns an action or '*Failure*\"\"\"\n",
    "        raise NotImplementedError() \n",
    "\n",
    "    # return the policy function\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450a7b58",
   "metadata": {
    "id": "450a7b58"
   },
   "source": [
    "In a completely clear map, the robot should be able to make it to the hospital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588fd379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_in_empty_map():\n",
    "    problem = SearchAndRescueProblem()\n",
    "    policy = make_greedy_policy(problem)\n",
    "\n",
    "    # Empty map\n",
    "    state = State()\n",
    "    state.state_map[:, :] = 'C'\n",
    "    bel = BeliefState()\n",
    "    bel.state_map[:, :] = 'C'\n",
    "\n",
    "    s_or_f, final_state, final_bel = agent_loop(problem, state, policy, bel)\n",
    "    print('Final robot location', final_state.robot)\n",
    "    return s_or_f, final_state, final_bel\n",
    "\n",
    "greedy_in_empty_result = greedy_in_empty_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378734c9",
   "metadata": {},
   "source": [
    "Using our default map, the robot should at least make it a bit closer to the hospital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e009ee",
   "metadata": {
    "id": "37e009ee",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def greedy_in_default():\n",
    "    problem = SearchAndRescueProblem()\n",
    "\n",
    "    # Use default map\n",
    "    state = State()\n",
    "    bel = BeliefState()\n",
    "\n",
    "    policy = make_greedy_policy(problem)\n",
    "    s_or_f, final_state, final_bel = agent_loop(problem, state, policy, bel)\n",
    "    r, c = final_state.robot\n",
    "    hr, hc = final_state.hospital\n",
    "    distance = abs(hr - r) + abs(hc - c)\n",
    "    print('Final robot location', final_state.robot)\n",
    "    print('Final distance (should be < initial distance) =', distance)\n",
    "    return distance \n",
    "\n",
    "greedy_in_default_distance = greedy_in_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896752a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 6\n",
    "Grader.run_single_test_inline(TestProj1, \"test_06_safe_not_smart\", locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed43cdb6",
   "metadata": {
    "id": "ed43cdb6"
   },
   "source": [
    "### <a id=\"safe_smart\"></a> 3B. Safe and smart (7 points)\n",
    "\n",
    "Let's try and make an agent that is both safe and a little smarter (although probably still a bit too conservative). \n",
    "\n",
    "We will continue to run the belief update method that you implemented above for the rest of these cases, so we only need to worry about the policy.  \n",
    "\n",
    "* The first time the policy is called to generate an action, it should formulate, in PDDL, a planning problem to find a complete plan for moving people to the hospital that only traverses squares that are *known* not to have fire or walls (i.e., unknown cells are not traversable either), and returns the first step.\n",
    "\n",
    "* On subsequent calls to the policy, it should just return the next step of the plan.\n",
    "\n",
    "Just as we did in Section 1, we want you to use `pyperplan`.\n",
    "\n",
    "For reference, our solution is **15** line(s) of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c249406",
   "metadata": {
    "id": "7c249406"
   },
   "outputs": [],
   "source": [
    "def make_planner_policy(problem, planner):\n",
    "    # Keep memory of plan and which step we're on\n",
    "    status = {'plan': None, 'step': None}\n",
    "\n",
    "    def policy(belief):\n",
    "        \"\"\"Returns an action string or '*Failure*' or '*Success*'.\"\"\"\n",
    "        raise NotImplementedError() \n",
    "    \n",
    "    # return the policy function\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ae7e09",
   "metadata": {
    "id": "76ae7e09"
   },
   "source": [
    "Our safe-and-smart agent should be able to successfully rescue all 4 people and deliver them to the hospital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41779f8c",
   "metadata": {
    "id": "41779f8c"
   },
   "outputs": [],
   "source": [
    "def sar_policy_test():\n",
    "    problem = SearchAndRescueProblem()\n",
    "    base_planner = SearchAndRescuePlanner(search_algo=\"gbf\", heuristic=\"hff\")\n",
    "\n",
    "    def safe_smart_planner(state):\n",
    "        plan, time = base_planner.get_plan(state)\n",
    "        return plan\n",
    "\n",
    "    policy = make_planner_policy(problem, safe_smart_planner)\n",
    "    state = State()\n",
    "    # Observable\n",
    "    bel = BeliefState(state_map=state.state_map)\n",
    "    return agent_loop(problem, state, policy, bel)\n",
    "sar_policy_results = sar_policy_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 7\n",
    "Grader.run_single_test_inline(TestProj1, \"test_07_safe_smart\", locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b48263c-86c3-46f3-a761-44e2f7622833",
   "metadata": {},
   "source": [
    "### <a id=\"reckless\"></a> 3C. Reckless (7 points)\n",
    "\n",
    "For this and the remaining questions, we're not going to autograde your solutions, and we're not providing test cases. We've given you boxes to hold your implementation, but you will need to define your own tests cases, and in section 4, we'll ask you to do some analysis. \n",
    "\n",
    "First, let's try to make our agent more aggressive but still not step into the fire!   As we saw in 3.1, even if we make a plan that might cause us to move into the fire, just before we are about to take an action, we can know for sure whether there is fire in the square we are about to move into.   So, let's make an (almost) reckless replanning agent.\n",
    "\n",
    "* The first time the policy is called to generate an action, it should formulate in PDDL a planning problem to find a very optimistic  plan for moving people to the hospital that only traverses squares that are **not known to have** fire or walls (i.e., unknowns are fair game), and returns the first step.\n",
    "\n",
    "* On subsequent calls to the policy, if the next step in the plan is safe to execute given the updated belief, it should return that action.  Otherwise, it should make a new plan!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a7adb-189a-4485-b04d-9fbd6c411818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reckless_policy(problem, planner):\n",
    "    # Keep memory of plan and which step we're on\n",
    "    status = {'plan': None, 'step': None}\n",
    "\n",
    "    def policy(belief):\n",
    "        \"\"\"Returns an action string or '*Failure*' or '*Success*'.\"\"\"\n",
    "        raise NotImplementedError() \n",
    "    \n",
    "    # return the policy function\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b751d-cc22-4df0-944d-cabc29392412",
   "metadata": {},
   "source": [
    "Use the code below to run your policy and provide an execution trace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38795870-e7c6-40b5-9f47-d1c9cc870fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reckless_policy_test():\n",
    "    problem = SearchAndRescueProblem()\n",
    "    base_planner = SearchAndRescuePlanner(search_algo=\"gbf\", heuristic=\"hff\")\n",
    "\n",
    "    def reckless_planner(state):\n",
    "        plan, time = base_planner.get_plan(state)\n",
    "        return plan\n",
    "\n",
    "    policy = make_reckless_policy(problem, reckless_planner)\n",
    "    state = State()\n",
    "    # Observable\n",
    "    bel = BeliefState(state_map=state.state_map)\n",
    "    s_or_f, final_state, final_bel = agent_loop(problem, state, policy, bel)\n",
    "reckless_policy_test() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3da4137-5473-44a2-8f62-f299d06ae75f",
   "metadata": {},
   "source": [
    "### <a id=\"safe_smart_reckless\"></a> 3D. Safe and smart if possible, else reckless (7 points)\n",
    "\n",
    "Try to construct a new policy that is a useful combination of \"safe and smart\" and \"reckless\" strategies, which combines the best aspects of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55fc3ef-f95b-49cc-b474-7968427e8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hybrid_policy(problem, planner):\n",
    "    # Keep memory of plan and which step we're on\n",
    "    status = {'plan': None, 'step': None}\n",
    "\n",
    "    def policy(belief):\n",
    "        \"\"\"Returns an action string or '*Failure*' or '*Success*'.\"\"\"\n",
    "        raise NotImplementedError() \n",
    "    \n",
    "    # return the policy function\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6739c01c-64f5-4165-b327-169145f4ee48",
   "metadata": {},
   "source": [
    "Use the code below to run your policy and provide an execution trace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4b3b7d-0d02-454b-bf06-da77b7507fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_policy_test():\n",
    "    problem = SearchAndRescueProblem()\n",
    "    base_planner = SearchAndRescuePlanner(search_algo=\"gbf\", heuristic=\"hff\")\n",
    "\n",
    "    def hybrid_planner(state):\n",
    "        plan, time = base_planner.get_plan(state)\n",
    "        return plan\n",
    "\n",
    "    policy = make_hybrid_policy(problem, hybrid_planner)\n",
    "    state = State()\n",
    "    # Observable\n",
    "    bel = BeliefState(state_map=state.state_map)\n",
    "    s_or_f, final_state, final_bel = agent_loop(problem, state, policy, bel)\n",
    "hybrid_policy_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdc1233-1d85-42e8-a532-dac3aa1bdfe9",
   "metadata": {},
   "source": [
    "### <a id=\"look_before\"></a> 3E. Looks before it leaps (7 points)\n",
    "\n",
    "Another way to approach this problem is to plan in belief space.  That sounds fancy, but actually can be relatively simple to do:\n",
    "\n",
    "* In your PDDL formulation, instead of just having a fluent `(is-clear ?loc)`, we'll have two fluents:  `(is-clear ?loc)` and `(is-unknown ?loc)`.\n",
    "\n",
    "* The precondition for moving into a square should still be `(is-clear ?loc)`.\n",
    "\n",
    "* You can add an operator that explicitly \"looks\" at a neighboring square;  we'll assume that it's optimistic and so if you look at a square that was previously unknown, it is now known to be clear.\n",
    "\n",
    "* Note that you can define a [subclass](https://www.geeksforgeeks.org/python/create-a-python-subclass/) of `SearchAndRescuePlanner` and redefine the `update_pddl_domain` method to add to the previous PDDL domain definition.  You'll also need to change the `parse_plan` method to handle the new action and the `get_init_strs` method to handle the new facts.\n",
    "\n",
    "* Make a replanning policy that plans in this belief-space formulation and executes its plan as long as it's safe, and replans otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0072c2ab-7a7d-4a48-a308-48b5d84cff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_belief_space_policy(problem, planner):\n",
    "    # Keep memory of plan and which step we're on\n",
    "    status = {'plan': None, 'step': None}\n",
    "\n",
    "    def policy(belief):\n",
    "        \"\"\"Returns an action string or '*Failure*' or '*Success*'.\"\"\"\n",
    "        raise NotImplementedError() \n",
    "    \n",
    "    # return the policy function\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417f517b-c45a-4ecb-b9f1-fd6be7c8cddb",
   "metadata": {},
   "source": [
    "Use the code below to run your policy and provide an execution trace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d34a4-5eb4-47ea-9af0-4d9fdfc2c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def belief_space_policy_test():\n",
    "    problem = SearchAndRescueProblem()\n",
    "    base_planner = SearchAndRescuePlanner(search_algo=\"gbf\", heuristic=\"hff\")\n",
    "\n",
    "    def belief_space_planner(state):\n",
    "        plan, time = base_planner.get_plan(state)\n",
    "        return plan\n",
    "\n",
    "    policy = make_belief_space_policy(problem, belief_space_planner)\n",
    "    state = State()\n",
    "    # Observable\n",
    "    bel = BeliefState(state_map=state.state_map)\n",
    "    s_or_f, final_state, final_bel = agent_loop(problem, state, policy, bel)\n",
    "belief_space_policy_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19028585-5ce2-4b41-abf0-4f9905bcea65",
   "metadata": {},
   "source": [
    "## <a id=\"analysis\"></a> 4. Analysis (30 points)\n",
    "\n",
    "In the following questions, please provide textual answers in the provided boxes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383a1881-2ffa-48f9-bd14-7116f235efd1",
   "metadata": {},
   "source": [
    "**First-order Logic:** In what way would having access to first-order logic have been helpful in this problem?\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baac1ad-544c-478f-b9dc-d460044e40f1",
   "metadata": {},
   "source": [
    "--> *(double click on this cell to delete this text and type your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c8d742-57a7-479a-b40d-7ed0a19d25d6",
   "metadata": {},
   "source": [
    "**Heuristics:** The heuristics used in `pyperplan` are *domain-independent*; we can use them for Search and Rescue, for blocks world, etc.  An alternative strategy would be to hand-specify a *domain-specific* heuristic. What would a good domain-specific heuristic for search and rescue look like?\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9858dd-f65e-447d-a0fd-ef826ca078b8",
   "metadata": {},
   "source": [
    "--> *(double click on this cell to delete this text and type your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559529cf-3b43-46f5-b118-29aea1d36d48",
   "metadata": {},
   "source": [
    "**Look first:** We do one observation before choosing our first action.  Give an example scenario where omitting this step and using the reckless or two-phase planner would make an error.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b71fad3-18aa-4ebf-b688-4298fae0ca25",
   "metadata": {},
   "source": [
    "--> *(double click on this cell to delete this text and type your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb7f52f-8db0-4907-9401-ac5d0d7ba684",
   "metadata": {},
   "source": [
    "**Replanning:**  Currently, for the policies in 3.3-3.4, we replan whenever executing the next step would be unsafe. That might not be the best replanning strategy. Describe another strategy, give a concrete example of where it would do something differently than the current strategy,\n",
    "and say what the general trade-offs would be between that one and the current one.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7a1f86-ee7b-4777-9f91-795b88b7c725",
   "metadata": {},
   "source": [
    "--> *(double click on this cell to delete this text and type your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7516b84-4687-4b77-a493-82c4a2fff8ce",
   "metadata": {},
   "source": [
    "**Planner Analysis:** Using the `test_policy` function, run your policies in the following three scenarios, specifically run:\n",
    "* The safe-and-smart planner\n",
    "* The reckless planner\n",
    "* The belief-space (looks before it leaps) planner\n",
    "    with the scenarios defined as:\n",
    "    * belief_map = P1_B0, true_map = P1_G0\n",
    "    * belief_map = P1_B1, true_map = P1_G0\n",
    "    * belief_map = P2_B1, true_map = P2_G0\n",
    "\n",
    "(These belief maps and true maps are all defined in the utility code at the top of this notebook.) \n",
    "\n",
    "In your answer below, don't count \"look\" as a step.\n",
    "* How many steps does each policy take to solve each problem?\n",
    "* Which method takes the fewest steps summed over all three problems?\n",
    "* Which one would you choose if planning is very expensive compared to execution?\n",
    "* Which one would you choose if execution is very expensive compared to planning? (In this case, what additional modifications might you make to your method)?\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f1f0d-6864-419c-b980-dc4b7ee92d76",
   "metadata": {},
   "source": [
    "--> *(double click on this cell to delete this text and type your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc79830-b216-4ff8-9b0a-2355abd933ce",
   "metadata": {},
   "source": [
    "# Submission \n",
    "\n",
    "Your final submission to gradescope should include this notebook, with all cells run to display your example runs and your text answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3706500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all tests\n",
    "Grader.grade_output([TestProj1], [locals()], \"results.json\")\n",
    "Grader.print_test_results(\"results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eec77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package submission\n",
    "# Make sure you save the notebook before running this cell so that the most updated version is zipped!\n",
    "Grader.prepare_submission(\"Project01_release\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982949ec-8089-44eb-bd51-f71eae1b20e0",
   "metadata": {},
   "source": [
    "## Feedback <a id=\"feedback\"></a>\n",
    "\n",
    "If you have any feedback for us, please complete [this form](https://forms.gle/auNaHZ9sJyKcGJ4s9)!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "mp01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
